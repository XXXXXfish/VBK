{
  "subjects": [
    {
      "id": "os",
      "name": "操作系统",
      "questions": [
        {
          "id": "os-q1",
          "question": "进程和线程的主要区别是什么？",
          "answer": "- 基本单位：\n  - 进程：是操作系统资源分配（内存、文件句柄等）的基本单位。\n  - 线程：是CPU调度（执行）的基本单位，一个进程可以包含多个线程。\n- 内存空间：\n  - 进程：拥有独立的内存地址空间，相互隔离。\n  - 线程：共享同一个进程的内存地址空间，包括代码段、数据段、堆等，但每个线程有独立的栈和寄存器。\n- 通信方式：\n  - 进程：需要使用进程间通信（IPC）机制（如管道、消息队列、共享内存等）进行通信。\n  - 线程：由于共享内存空间，可以直接读写共享数据进行通信，但需要同步机制（如互斥锁、信号量）来保证数据一致性。\n- 安全性/独立性：\n  - 进程：一个进程的崩溃通常不会影响其他进程，因为它们相互隔离。\n  - 线程：一个线程的崩溃（例如访问非法内存）可能导致整个进程崩溃，进而影响其他线程。\n- 开销：\n  - 进程：创建、销毁、切换的开销相对较大。\n  - 线程：创建、销毁、切换的开销相对较小。"
        },
        {
          "id": "os-q2",
          "question": "常见的进程调度算法有哪些？",
          "answer": "常见的进程调度算法包括：\n- 先来先服务（FCFS, First-Come-First-Served）：最简单的调度算法，按照进程到达的先后顺序进行调度。非抢占式，对短进程不利。\n- 短作业优先（SJF, Shortest Job First）：优先调度预计运行时间最短的进程。非抢占式（SJF）或抢占式（SRTF，最短剩余时间优先），平均周转时间最短，但难以准确预估运行时间，可能导致长进程饥饿。\n- 最高响应比优先（HRRN, Highest Response Ratio Next）：综合考虑作业的等待时间和运行时间，避免SJF可能导致的饥饿现象。响应比 = (等待时间 + 运行时间) / 运行时间。\n- 时间片轮转（RR, Round Robin）：为每个进程分配一个固定的时间片，进程用完时间片后被剥夺CPU，放到就绪队列末尾。适用于分时系统，公平性好，但上下文切换开销较大。\n- 优先级调度（Priority Scheduling）：为每个进程分配一个优先级，优先调度优先级高的进程。可能导致低优先级进程饥饿，可通过老化（aging）技术解决。\n- 多级反馈队列调度（Multilevel Feedback Queue）：结合了时间片轮转和优先级调度，设置多个就绪队列，每个队列有不同的优先级和时间片大小。新进程进入最高优先级队列，用完时间片未完成则降级。兼顾了响应时间和周转时间。"
        },
        {
          "id": "os-q3",
          "question": "进程间通信（IPC）的常见方式有哪些？",
          "answer": "进程间通信（IPC, Inter-Process Communication）是不同进程之间进行数据交换和协调的机制，常见方式有：\n- 管道（Pipe）：\n  - 匿名管道 (|)：只能用于具有亲缘关系的进程（如父子进程）之间通信，数据单向流动，半双工。通过 pipe() 系统调用创建。\n  - 命名管道 (mkfifo)：以文件形式存在于文件系统中，允许不具备亲缘关系的进程进行通信，数据遵循先进先出（FIFO）原则，半双工。\n- 消息队列（Message Queue）：\n  - 存放在内核中的消息链表，允许进程向其中添加消息，或从其中读取消息。具有独立于发送和接收进程的生命周期，支持异步通信。\n  - 可以实现系统解耦、流量削峰和可靠数据传输，像“小区里的快递柜”。\n- 共享内存（Shared Memory）：\n  - 允许不同进程映射同一块物理内存区域到各自的虚拟地址空间，从而直接读写内存，实现最快的数据传输速度。\n  - 需要通过信号量、互斥锁等同步机制来避免竞态条件。\n  - 适用于频繁交换大数据量的场景。\n- 信号量（Semaphore）：\n  - 维护一个计数器，通过原子操作（P操作：申请资源，计数器减1，资源不足则阻塞；V操作：释放资源，计数器加1，唤醒等待进程）来控制对共享资源的访问，实现进程的同步与互斥。\n- 信号（Signal）：\n  - 异步的进程间通信机制，通过软件中断的方式通知进程发生了特定事件（如Ctrl+C会发送SIGINT信号），允许进程或内核以非阻塞方式传递简单消息并触发预定义的处理动作。\n- 套接字（Socket）：\n  - 用于不同设备间（也可以是同一设备内不同进程间）数据传输的端点，通过IP地址和端口号唯一标识。为应用程序提供基于TCP/UDP等协议的双向通信接口。\n  - 本质上是一种特殊的“文件”，创建时系统分配文件描述符，可像读写文件一样读写Socket。"
        },
        {
          "id": "os-q4",
          "question": "什么是死锁？产生死锁的四个必要条件和解决策略？",
          "answer": "死锁概念：\n死锁是指多个进程在执行过程中，因争夺系统资源而造成的一种互相等待对方释放资源才能继续执行的现象，若无外力干涉，它们都将无法继续进行下去。\n\n死锁的四个必要条件：\n1.  资源互斥：资源在一段时间内只能被一个进程占用。即当一个进程已占用了某资源，其他进程就不能再申请该资源。\n2.  请求与保持（Hold and Wait）：进程因得不到某些资源而阻塞时，不会释放自己已经占有的资源。\n3.  不可剥夺：进程已获得的资源在未使用完之前，不能被强行剥夺，只能由拥有该资源的进程自主释放。\n4.  环路等待：在资源分配图中，存在一个进程-资源环路，即P0等待P1，P1等待P2，...，Pn等待P0。\n\n解决死锁的策略：\n- 预防死锁（Prevent Deadlock）：破坏死锁的四个必要条件之一或多个。\n  - 破坏“请求与保持”：要求进程一次性申请所有所需的资源，或在申请新资源时必须释放当前持有的所有资源。\n  - 破坏“不可剥夺”：允许系统剥夺进程已经占有的资源（例如，当进程申请新资源失败时，强制它释放已占有的资源）。\n  - 破坏“环路等待”：对资源进行线性排序，要求进程按序申请资源。\n- 避免死锁（Avoid Deadlock）：在资源动态分配过程中，用算法确保系统始终处于安全状态（如银行家算法）。\n- 检测死锁（Detect Deadlock）：允许系统进入死锁状态，但提供检测机制，可以判断是否存在死锁。\n- 解除死锁（Recover from Deadlock）：检测到死锁后，采取措施（如终止进程、剥夺资源）来解除死锁。"
        },
        {
          "id": "os-q5",
          "question": "什么是虚拟内存？为什么要引入虚拟内存？",
          "answer": "虚拟内存概念：\n虚拟内存是计算机系统内存管理的一种技术，它使得应用程序认为自己拥有一个连续的、巨大的（通常比实际物理内存大得多）地址空间，而实际上这片空间可能被分割成多个物理内存碎片，甚至一部分数据存储在磁盘上。\n\n引入虚拟内存的原因/作用：\n1.  内存扩展：允许程序使用比实际物理内存（RAM）更多的内存空间。当物理内存不足时，操作系统会将不常用（或当前不活跃）的程序代码和数据暂时从物理内存移动到硬盘上的交换空间（Swap Space），腾出物理内存给当前活跃的程序使用。这使得程序可以运行得更大，系统可以同时运行更多的程序。\n2.  内存隔离/保护：每个进程都有自己独立的虚拟地址空间。这意味着一个进程无法直接访问另一个进程的内存，从而提高了系统的安全性和稳定性，防止一个进程的错误影响到其他进程或操作系统本身。\n3.  多道程序设计：简化了多道程序的内存管理。每个程序都可以被编译到从零开始的虚拟地址空间，操作系统负责将这些虚拟地址映射到实际的物理地址，无需程序员关心物理内存的分配细节。\n4.  内存共享：通过将同一块物理内存映射到多个进程的虚拟地址空间，可以实现进程间的高效数据共享（如共享库）。\n5.  按需加载：程序在执行时，并非所有代码和数据都会一次性加载到物理内存。虚拟内存机制允许操作系统只加载程序中当前需要的部分到物理内存，其他部分等到需要时再从磁盘加载，提高了内存利用率和程序启动速度。"
        },
        {
          "id": "os-q6",
          "question": "内存分段和内存分页的区别和作用？",
          "answer": "内存分段（Segmentation）：\n- 概念：将程序按其逻辑结构（如代码段、数据段、堆栈段、子程序等）划分为若干个大小可变的段，以段为单位装入内存。\n- 作用：\n  - 逻辑独立性：每个段描述一个独立的逻辑功能模块，便于程序员和操作系统对内存布局进行逻辑控制和管理。\n  - 内存保护：通过段表中的权限位（读/写/执行）实现更精细的内存保护，防止非法访问。\n  - 共享：便于实现程序的共享，如共享库代码。\n  - 按需加载：可以按需加载某个段，无需完整加载整个程序。\n- 缺点：段大小可变导致外部碎片问题。\n\n内存分页（Paging）：\n- 概念：将程序的虚拟地址空间和物理内存空间都划分为若干个大小固定的、等长的块。虚拟地址空间的块称为“页”（Page），物理内存的块称为“页框”（Page Frame）或“物理块”。操作系统以页为单位进行内存管理和数据传输。\n- 作用：\n  - 消除外部碎片：由于页和页框大小固定，可以有效地利用所有空闲的物理内存块，避免了外部碎片问题（但可能存在内部碎片）。\n  - 简化内存分配与回收：内存分配和回收都以固定大小的页为单位，简化了管理流程。\n  - 物理内存非连续：逻辑上连续的页可以分散地存放在物理内存的非连续页框中，提高了内存利用率。\n- 缺点：页的大小固定，可能导致内部碎片（最后一个页未被完全利用）。\n\n主要区别：\n- 划分依据：分段基于程序逻辑结构，分页基于内存物理结构。\n- 大小：段的大小是可变的，页的大小是固定的。\n- 碎片：分段易产生外部碎片，分页易产生内部碎片。\n- 地址：分段地址由段号+段内偏移构成，分页地址由页号+页内偏移构成。"
        },
        {
          "id": "os-q7",
          "question": "什么是用户态和内核态？为什么要区分这两种状态？",
          "answer": "用户态（User Mode）：\n- 权限：较低的权限级别。应用程序在此模式下运行。\n- 访问：只能访问受限的系统资源和内存空间。如果需要访问硬件设备或执行特权指令，必须通过系统调用（System Call）向操作系统内核请求服务。\n\n内核态（Kernel Mode）/ 管态（Supervisor Mode）：\n- 权限：最高的权限级别。操作系统内核在此模式下运行。\n- 访问：可以访问系统的所有硬件设备和任意内存地址，执行任何CPU指令。\n\n为什么要区分用户态和内核态？\n1.  安全性：\n    - 内核态：是操作系统内核运行的状态，拥有最高权限，可以访问系统的所有资源，像硬件设备、内存空间等。而用户态是应用程序运行的状态，在用户态下应用程序的权限受到严格限制，不能随意访问关键资源，防止恶意程序或编程错误随意篡改系统核心数据或硬件配置。\n    - 通过用户态/内核态的隔离，用户程序被限制在受保护的环境中运行。\n2.  稳定性：\n    - 内核负责管理和调度系统中的所有资源（如CPU调度、内存管理、I/O操作）。将这部分功能隔离在内核态，可以确保其稳定运行，不受用户程序干扰。\n    - 即便某个用户程序崩溃，通常也只影响该程序自身，而不会拖垮整个操作系统。\n3.  高效性/资源管理：\n    - 内核态可以对系统资源进行统一且高效的管理和调度。应用程序在用户态只需专注于自身的业务逻辑，当需要访问受保护的资源（如读写文件、网络通信）时，通过系统调用主动请求内核的服务。\n    - 这种机制使得内核能够集中管理和优化资源分配，提高了整个系统的运行效率和资源利用率。\n\n总结：用户态和内核态是操作系统提供的一种硬件级别的保护机制，用于隔离应用程序和操作系统内核，确保系统在多任务和多用户环境下的安全、稳定和高效运行。"
        },
        {
          "id": "os-q8",
          "question": "常见的页面置换算法有哪些？",
          "answer": "页面置换算法是在虚拟内存管理中，当发生缺页（Page Fault）且物理内存已满时，决定将哪个物理页框中的内容换出到磁盘，以腾出空间加载新页的算法。\n\n常见的页面置换算法有：\n1.  最佳置换算法（OPT, Optimal Page Replacement）：\n    - 原理：选择未来最长时间内不再使用的页面淘汰。理论上性能最佳。\n    - 实现：无法实现，因为它需要预知程序未来的访问序列，用于理论分析比较其他算法。\n2.  先进先出置换算法（FIFO, First-In-First-Out）：\n    - 原理：优先淘汰最先进入内存的页面。实现简单。\n    - 实现：使用一个队列，记录页面进入内存的顺序。每次淘汰队头页面。\n    - 缺点：可能出现“Belady现象”，即增加物理内存页框数反而导致缺页次数增加。可能淘汰经常使用的页面。\n3.  最近最少使用置换算法（LRU, Least Recently Used）：\n    - 原理：优先淘汰最长时间未使用的页面。具有较好的性能，因为它基于“局部性原理”（过去频繁使用的页面，未来也可能频繁使用）。\n    - 实现：需要记录页面的使用时间或访问顺序。可以利用栈、链表（更新访问时间）、计数器或特殊的硬件支持实现。开销较大。\n4.  最不经常使用置换算法（LFU, Least Frequently Used）：\n    - 原理：优先淘汰在一段时间内使用次数最少的页面。\n    - 实现：为每个页面维护一个计数器，每次访问页面时计数器加1。淘汰计数器值最小的页面。\n    - 缺点：实现复杂。如果一个页面在早期频繁使用，但之后不再使用，其计数器可能仍然很高，导致其长期不被淘汰。"
        },
        {
          "id": "os-q9",
          "question": "进程同步和互斥的概念及解决办法？",
          "answer": "进程同步 (Synchronization)：\n- 概念：指多个进程在一些操作上存在逻辑上的先后顺序，为了完成共同任务而需要协同工作，互相等待和协调的机制。\n- 例子：生产者-消费者问题（生产者生产数据，消费者消费数据，必须先生产后消费）。\n\n进程互斥 (Mutual Exclusion)：\n- 概念：指多个进程在访问同一个独占性共享资源（临界资源，如打印机、共享变量、文件）时，必须以独占的方式进行，即在同一时刻只允许一个进程访问该资源。\n- 例子：多个进程修改同一个计数器变量。\n\n解决进程同步和互斥的常见方法：\n1.  信号量（Semaphore）：\n    - 概念：一个整型变量，用于表示可用资源的数量。通过P操作（Wait/down）和V操作（Signal/up）两个原子操作来控制共享资源的访问。\n    - P操作：申请资源。信号量减1。如果结果小于0，表示资源不足，进程阻塞。\n    - V操作：释放资源。信号量加1。如果结果小于等于0，表示有等待进程被唤醒。\n    - 用法：可用于实现互斥（将信号量初始化为1，作为二值信号量，即互斥锁）和同步（控制多个进程的执行顺序）。\n2.  互斥锁（Mutex, Mutual Exclusion Lock）：\n    - 概念：是一种特殊的二值信号量，用于保护临界区，确保在任何时刻只有一个线程/进程能进入临界区。\n    - 操作：lock()（加锁）和unlock()（解锁）。当一个线程尝试获取已被其他线程持有的互斥锁时，该线程会被阻塞并进入睡眠状态，释放CPU。\n3.  条件变量（Condition Variable）：\n    - 概念：通常与互斥锁配合使用，用于在某个条件不满足时，让线程进入睡眠状态等待，直到条件满足时被唤醒。用于线程间的协作。\n4.  读写锁（Read-Write Lock）：\n    - 概念：允许多个读线程同时访问共享资源，但写线程是独占的，即在写线程访问资源时，不允许其他读写线程访问。\n5.  原子操作（Atomic Operations）：\n    - 概念：对于简单的变量操作（如整型加减），可以直接使用硬件提供的原子指令，无需加锁，效率更高。\n6.  屏障（Barrier）：\n    - 概念：用于等待一组线程都达到某个共同点后才能继续执行。实现线程的集体同步。\n7.  自旋锁（Spinlock）：\n    - 概念：在等待锁释放时，线程不休眠而是忙循环检查。适用于临界区极短的场景。"
        },
        {
          "id": "os-q10",
          "question": "中断和异常的区别及作用？中断的来源？",
          "answer": "中断（Interrupt）：\n- 来源：通常由外部设备（如I/O完成、定时器到期、用户按下键盘）或外部事件（如电源故障）产生。\n- 同步性：是异步的，在任何指令执行完成后都可能发生，与当前CPU正在执行的指令无关。\n- 可屏蔽性：通常可以被屏蔽（CPU可以暂时忽略某些中断请求）。\n- 作用：协调CPU与外设的速度差异，提高资源利用率；实现实时响应与高效事件处理；支持多任务与并行操作（如时间片轮转）。\n\n异常（Exception）：\n- 来源：由CPU内部事件引起，是当前正在执行的指令的直接结果（例如除以零、访问非法内存地址、缺页故障、执行非法指令、系统调用）。\n- 同步性：是同步的，只发生在特定指令执行时。\n- 可屏蔽性：通常不可屏蔽。\n- 作用：处理程序错误、实现虚拟内存管理、提供系统调用接口。\n\n中断的作用：\n- 协调CPU与外设：处理外设的请求（如数据传输完成），使CPU不必等待外设，提高CPU利用率。\n- 实现多任务：通过定时器中断实现时间片轮转，使多个进程轮流占用CPU。\n- 错误处理：处理硬件故障等突发事件。\n\n中断的来源：\n- 外设中断：I/O设备完成操作、键盘鼠标事件、网络数据到达等。\n- 定时器中断：由系统定时器产生，用于调度、时间计量等。\n- CPU异常（内中断）：\n  - 陷阱（Trap）：故意的，如系统调用指令（int 80h在Linux中），主动陷入内核以获取特权服务。\n  - 故障（Fault）：可恢复的，如缺页故障（Page Fault），CPU会尝试修复并重新执行出错指令。\n  - 中止（Abort）：不可恢复的严重错误，如硬件故障，导致程序甚至系统崩溃。\n- 软中断/中断指令：由软件指令显式触发的内部中断，通常用于实现系统调用。\n\n总结：中断是外部事件的异步通知，异常是CPU执行指令时的同步错误或事件。"
        },
        {
          "id": "os-q11",
          "question": "几种典型的锁有什么区别？",
          "answer": "在多线程/多进程编程中，锁是用于实现同步和互斥的机制。常见的几种锁包括：\n1.  互斥锁（Mutex Lock）：\n    - 特性：提供排他性访问。当一个线程获取到互斥锁时，其他尝试获取该锁的线程会被阻塞（挂起），并进入睡眠状态，不占用CPU资源。直到持有锁的线程释放锁后，操作系统会唤醒等待队列中的一个线程。\n    - 场景：适用于临界区较长、竞争不激烈，或需要线程在等待时释放CPU资源的场景。\n    - 开销：上下文切换开销较大。\n\n2.  自旋锁（Spinlock）：\n    - 特性：当一个线程尝试获取已经被其他线程持有的自旋锁时，这个线程会忙循环（spin），不断地检查锁是否被释放，而不是被阻塞。线程始终占用着CPU。\n    - 场景：适用于临界区非常短、加锁时间极短、竞争激烈，且不希望发生上下文切换开销的场景（如内核态）。如果临界区过长，会导致CPU空转浪费资源。\n    - 开销：无上下文切换开销，但会占用CPU。\n\n3.  读写锁（Read-Write Lock）：\n    - 特性：允许多个读线程同时持有锁并访问共享资源，但只允许一个写线程独占地持有锁。当有写线程持有锁时，所有读写线程都将被阻塞。\n    - 场景：适用于读操作远多于写操作的共享资源，可以提高并发度。\n    - 优点：提高并发性。减少读读冲突。\n    - 缺点：实现相对复杂，可能存在写饥饿问题（写操作一直得不到锁）。\n\n总结：互斥锁通过阻塞线程来避免忙等，适用于临界区较长；自旋锁通过忙等来避免上下文切换，适用于临界区极短；读写锁通过区分读写权限来提升读的并发性。"
        },
        {
          "id": "os-q12",
          "question": "线程同步的常见方法有哪些？",
          "answer": "线程同步是为了协调多个线程的执行，确保它们对共享资源的访问是有序且正确的，避免竞态条件。常见线程同步方法包括：\n1.  互斥锁（Mutex）：\n    - 作用：最基本的同步机制，用于保护临界区，确保同一时刻只有一个线程访问共享资源。\n    - 原理：当线程尝试获取已被其他线程持有的锁时，会被阻塞。\n2.  信号量（Semaphore）：\n    - 作用：控制对共享资源的访问数量。可用于互斥（二值信号量）和同步（协调线程执行顺序）。\n    - 原理：通过P/V原子操作对计数器进行增减，实现资源的申请和释放。\n3.  条件变量（Condition Variable）：\n    - 作用：通常与互斥锁配合使用，用于线程间的协作。当某个条件不满足时，线程可以释放互斥锁并进入等待状态，直到其他线程改变条件并通知它。\n    - 操作：wait()（等待条件满足）和signal()或broadcast()（通知条件满足）。\n4.  读写锁（Read-Write Lock）：\n    - 作用：允许多个线程同时进行读操作，但只允许一个线程进行写操作。适用于读多写少的场景。\n    - 原理：区分读锁和写锁，读锁可共享，写锁独占。\n5.  原子操作（Atomic Operations）：\n    - 作用：对于简单的变量操作（如整型加减），可以直接使用硬件提供的原子指令，无需加锁，效率更高。\n    - 原理：由CPU保证操作的不可中断性。\n6.  屏障（Barrier）：\n    - 作用：用于等待一组线程都达到某个共同点后才能继续执行。实现线程的集体同步。\n7.  自旋锁（Spinlock）：\n    - 作用：在等待锁释放时，线程不休眠而是忙循环检查。适用于临界区极短的场景。"
        },
        {
          "id": "os-q13",
          "question": "写文件在操作系统内部的处理过程是怎样的？",
          "answer": "当应用程序发起写文件操作时，操作系统内部的处理过程通常如下：\n1.  用户态到内核态的切换：应用程序通过标准库函数（如C语言的fwrite、write）发起写文件的系统调用。这会触发一个软中断，使CPU从用户态切换到内核态，因为文件操作涉及到对硬件资源的访问，需要操作系统内核来管理和调度。\n2.  文件描述符和inode查找：内核根据系统调用中提供的文件描述符，查找进程的文件描述符表，找到对应的文件表项。文件表项指向inode（索引节点），inode包含了文件的元数据（如文件大小、创建/修改时间、权限以及文件在磁盘上的物理位置）。\n3.  数据拷贝到内核缓冲区：应用程序要写入的数据从用户空间的内存区域拷贝到内核空间的某个缓冲区（如页缓存 Page Cache）。这个过程由DMA（直接内存访问）或CPU进行。写入操作通常不会直接写入磁盘，而是先写入页缓存，以提高写入效率和聚合小写入。\n4.  数据写入磁盘（或等待）：内核会将缓冲区中的数据根据inode信息写入到磁盘上的对应位置。写入操作可能是同步的（立即写入磁盘）或异步的（由后台进程择机写入磁盘，如fsync可强制同步）。在写入磁盘的过程中，可能会涉及到磁盘调度算法（如电梯算法）来优化磁盘臂移动。\n5.  更新文件元数据：写入操作完成后，内核会更新文件的inode节点信息，例如更新文件大小、最后修改时间（mtime）、最后访问时间（atime）等。\n6.  切回用户态：文件写入操作完成后，内核通过返回系统调用的结果（成功或失败），将CPU从内核态切换回用户态，应用程序继续执行其后续代码。"
        },
        {
          "id": "os-q14",
          "question": "为什么操作系统要有用户态和内核态？",
          "answer": "操作系统之所以要有用户态和内核态，主要是为了实现安全性、稳定性、高效性和资源管理：\n1.  安全性：\n    - 内核态：是操作系统内核运行的状态，拥有最高权限，可以访问系统的所有硬件设备（CPU、内存、I/O控制器等）和所有内存空间，可以执行任何特权指令。\n    - 用户态：是应用程序运行的状态，权限受严格限制，不能直接访问关键硬件资源或修改操作系统核心数据结构。如果用户程序尝试执行特权操作，会立即触发异常，由内核介入处理。\n    - 这种隔离防止了恶意程序或编程错误随意篡改系统核心数据或硬件配置，从而保护了系统的安全。\n2.  稳定性：\n    - 内核负责管理和调度系统中的所有资源（CPU、内存、文件、网络等）。如果用户程序在内核态运行，任何一个程序的崩溃或错误都可能直接影响到其他程序甚至整个操作系统的稳定性，导致系统崩溃。\n    - 通过用户态/内核态的分离，即便一个用户程序崩溃，通常也只影响该程序自身，而不会波及到操作系统或其他正在运行的程序，从而保证了系统的整体稳定性。\n3.  高效性与资源管理：\n    - 内核态可以对系统资源进行统一且高效的管理和调度。应用程序在用户态只需专注于自身的业务逻辑，当需要访问受保护的资源（如读写文件、网络通信）时，通过系统调用主动请求内核的服务。\n    - 这种机制使得内核能够集中管理和优化资源分配，避免了应用程序之间的资源冲突，提高了整个系统的运行效率和资源利用率。\n\n总结：用户态和内核态是操作系统提供的一种硬件级别的保护机制，用于隔离应用程序和操作系统内核，确保系统在多任务和多用户环境下的安全、稳定和高效运行。"
        },
        {
          "id": "os-q15",
          "question": "Linux中常见的进程状态有哪些？",
          "answer": "Linux系统中，进程在其生命周期中会经历多种状态，主要包括：\n1.  运行（R, Running）状态：\n    - 进程要么正在CPU上执行（TASK_RUNNING），要么已经准备好，等待调度器分配CPU资源（处于就绪队列中）。\n2.  睡眠（S, Interruptible Sleep）状态：\n    - 可中断睡眠状态（TASK_INTERRUPTIBLE）。进程因等待某个事件（如I/O操作完成、获取资源锁）而暂时停止执行。可以被信号（signal）中断，响应信号并去处理其他事情。\n3.  深度睡眠（D, Uninterruptible Sleep）状态：\n    - 不可中断睡眠状态（TASK_UNINTERRUPTIBLE）。进程通常在等待一些硬件I/O操作（如磁盘I/O）完成。处于此状态的进程不会响应信号，直到等待的硬件资源就绪，因此不能被外部信号中断或杀死，只能等待操作完成或系统重启。\n4.  暂停（T, Stopped）状态：\n    - 进程收到了SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOU等信号而暂停执行。进程不占用CPU资源，但保留着运行时的状态，当收到SIGCONT信号后，会接着之前暂停的地方继续运行。\n    - 调试程序（如GDB）跟踪的进程也可能处于TASK_TRACED（跟踪）状态，在ps命令中也显示为T。\n5.  僵死（Z, Zombie）状态：\n    - 也叫僵尸状态（TASK_DEAD -> EXIT_ZOMBIE）。子进程运行结束，但其父进程还没有调用wait()或waitpid()系统调用来获取子进程的终止状态时，子进程就会进入僵死状态。此时，进程已经释放了大部分资源，但在进程表中还保留一个很小的条目，用于向父进程传递终止信息。\n    - 僵尸进程是一个只占用少量资源但不会自行消亡的进程，需要父进程来“收尸”。如果父进程先于子进程结束，僵尸进程会被init进程领养并清理。\n6.  退出（X, Dead）状态：\n    - 进程已经完全终止，所有资源已被回收。这是一个瞬态，通常在ps命令中难以看到。"
        }
      ]
    },
    {
      "id": "mysql",
      "name": "MySQL",
      "questions": [
        {
          "id": "mysql-q1",
          "question": "更新一条数据，数据库内部发生了什么？",
          "answer": "更新一条数据时，数据库内部通常会经历以下过程：\n1. 客户端发送更新请求：应用程序（客户端）向MySQL数据库发送一个UPDATE SQL语句。\n2. 数据库验证身份和权限：数据库服务器接收请求后，首先验证客户端的身份（用户认证）和是否有权限对目标表进行UPDATE操作。\n3. SQL解析器解析SQL语句：解析器检查SQL语句的语法是否正确，并将其分解成数据库内部可理解的结构（如解析树或AST）。\n4. 查询优化器生成执行计划：查询优化器分析这个更新请求，查找可用的索引，评估不同的执行路径（例如是全表扫描还是走索引），并选择一个最高效的执行计划来定位和修改数据。\n5. 事务开始：即使你没有显式地使用 BEGIN TRANSACTION，大多数数据库（特别是InnoDB存储引擎）也会为你的UPDATE语句自动开启一个隐式事务。\n6. 记录到重做日志（Redo Log）缓冲区：在数据真正写入磁盘之前，数据库会把所有修改操作的详细信息记录到重做日志缓冲区（redo log buffer），这是实现事务持久性和故障恢复的关键。\n7. 对数据行加锁：数据库对将要修改的数据行加锁（通常是行级排他锁X锁），以防止其他并发事务对同一行数据进行冲突修改。\n8. 数据页加载与内存修改：数据库从磁盘读取需要更新的数据页到缓冲池（Buffer Pool）。然后在内存中修改对应的数据行，将新值写入。\n9. 记录到回滚日志（Undo Log）：修改数据之前，数据库会将该行数据的旧值记录到Undo Log回滚日志。Undo Log是实现事务原子性、MVCC和事务回滚的基础。\n10. 刷入重做日志：在事务提交前（或在某个检查点），确保所有与该事务相关的重做日志记录都已经从缓冲区刷入到磁盘上的重做日志文件，保证持久性。\n11. 释放锁：事务提交成功后，数据库释放对数据行持有的锁。\n12. 标记脏页：缓冲池中被修改的数据页被标记为“脏页”（dirty page），表示其内容与磁盘上的不一致。脏页会在后台由专门的线程择机刷写回磁盘。"
        },
        {
          "id": "mysql-q2",
          "question": "事务隔离级别有哪些？分别解决和带来的问题？",
          "answer": "事务隔离级别定义了一个事务可能受到其他并发事务影响的程度。SQL标准定义了四种隔离级别，隔离级别越高，数据一致性越好，但并发性能越差。\n\n四种隔离级别：\n1.  读未提交（Read Uncommitted）：\n    - 概念：事务可以读取到另一个事务尚未提交的数据修改。\n    - 导致问题：脏读（Dirty Read）。\n    - 优点：并发性能最高，但数据一致性最差。\n2.  读已提交（Read Committed）：\n    - 概念：一个事务只能读取到其他事务已经提交的数据。\n    - 解决问题：脏读。\n    - 导致问题：不可重复读（Non-Repeatable Read）和幻读（Phantom Read）。\n    - 优点：比读未提交有更高的一致性，是许多数据库（如Oracle、PostgreSQL）的默认隔离级别。\n3.  可重复读（Repeatable Read）：\n    - 概念：MySQL 默认的隔离级别。一个事务在执行过程中，多次读取同一行数据，其结果始终保持一致。\n    - 解决问题：脏读、不可重复读。\n    - 导致问题：幻读（在RR级别下，MySQL通过MVCC解决了大部分幻读，但范围插入仍可能导致幻读）。\n    - 优点：在保证数据一致性的同时，有较好的并发性能。\n4.  可串行化（Serializable）：\n    - 概念：最高的隔离级别。所有事务都是串行执行的，即强制事务按顺序依次执行。\n    - 解决问题：脏读、不可重复读、幻读。\n    - 导致问题：并发性能很低，因为事务需要排队执行。\n\n常见并发问题：\n- 脏读（Dirty Read）：一个事务读取到了另一个事务尚未提交的数据修改。如果那个事务最终回滚，那么读取到的数据就是“脏”的。\n- 不可重复读（Non-Repeatable Read）：一个事务在两次查询同一数据时，发现数据已经被另一个已提交的事务修改，导致两次读取结果不一致。\n- 幻读（Phantom Read）：一个事务在两次查询相同范围的数据时，第二次查询发现比第一次多出来一些数据，这是别的事务新插入的并已提交，就像出现了幻觉。"
        },
        {
          "id": "mysql-q3",
          "question": "事务的ACID四大特性是什么？",
          "answer": "事务的ACID特性是数据库管理系统（DBMS）为确保数据库操作的可靠性而提供的一组基本属性，确保数据处理的正确性和完整性。ACID分别代表：\n1.  原子性（Atomicity）：\n    - 概念：事务是数据库的逻辑工作单位，一个事务包含的所有操作，要么全部成功执行，要么全部失败回滚。事务是不可分割的最小操作单元。\n    - 保证：通过Undo Log（回滚日志）实现，当事务失败时，利用Undo Log将数据恢复到事务开始前的状态。\n2.  一致性（Consistency）：\n    - 概念：事务执行的结果必须是从一个一致性状态变到另一个一致性状态。一致性意味着数据库中的数据满足所有的完整性约束（如主键约束、外键约束、唯一约束、检查约束）和业务逻辑定义。\n    - 保证：DB中只包含执行成功的事务，并且事务执行过程中，数据库的状态始终满足预定义的规则。\n3.  隔离性（Isolation）：\n    - 概念：事务之间互不干扰。当多个事务并发执行时，一个事务的执行不应影响其他并发事务。事务使用的数据对其他并发事务是隔离的，就好像每个事务都是独立、顺序执行的一样。\n    - 保证：通过锁机制和MVCC（多版本并发控制）来实现，防止并发事务之间的数据冲突。\n4.  持久性（Durability）：\n    - 概念：一旦事务提交成功，其对数据库中数据的改变就是永久性的，即使数据库系统发生故障（如系统崩溃、断电），这些改变也不会丢失。\n    - 保证：通过Redo Log（重做日志）实现，事务提交后，相关的修改会记录到Redo Log并刷入磁盘，即使数据尚未完全写入数据文件，系统重启后也能通过Redo Log恢复已提交的事务。"
        },
        {
          "id": "mysql-q4",
          "question": "什么是索引？索引有哪些类型？",
          "answer": "索引的概念：\n索引是一种特殊的数据结构，它存储了表中一列或多列的值，并对这些值进行排序，从而可以快速找到数据表中对应记录的物理位置。索引的创建通常会独立于数据本身，但在概念上与数据相关联。例如，对用户表的“年龄”列建立索引，数据库会开辟一块物理空间，将“年龄”值按顺序存储，每个节点存储键值对以及指向子节点的指针。\n- 普通索引创建一般不改变数据物理存储位置。\n- 当你定义某列为主键时，系统通常会自动创建一个聚簇索引（在InnoDB中）。\n\n索引类型（按结构）：\n1.  B+树索引：\n    - MySQL InnoDB的默认索引类型。\n    - 特点：所有数据都存在叶子节点，并且叶子节点之间用链表连接，适合范围查询（WHERE、JOIN、BETWEEN、GROUP BY、ORDER BY等）。查询复杂度为logn，查询性能稳定。\n    - 与B树比较：非叶子节点不存放实际的记录数据，仅存放索引键，因此在数据量相同的情况下，B+树相比B树更“矮胖”，查询底层节点的磁盘I/O次数会更少。叶子节点之间用链表连接，有利于范围查询，不需要遍历整棵树。B+树有大量的冗余索引，在插入、删除的效率都更高，不会发生复杂的树的变化。\n2.  哈希索引：\n    - 特点：基于哈希表实现，将索引列的值通过哈希函数映射到存储位置。只支持等值查询（如`WHERE col = value`），不支持范围查询或排序。\n    - 缺点：出现哈希冲突会降低查询效率。\n    - 适用场景：仅做等值查询，键值型访问场景（如内存数据库Redis内部使用哈希）。\n3.  全文索引：\n    - 特点：用于文本字段，适合自然语言检索、模糊匹配。数据库先对文本进行分词处理，然后记录每个词在文本中的位置等信息。\n    - 缺点：占用空间比普通索引更大；当原始文本数据发生变化时，全文索引需要更新。\n4.  空间索引：\n    - 特点：专门用于地理空间数据类型（如点、线、面），主要用于存储和查询地理位置信息。\n\n索引类型（按存储方式）：\n1.  聚簇索引（Clustered Index）：\n    - 特点：数据和索引一起存放，索引结构的叶子节点直接包含行的数据。找到索引就找到了数据本身。\n    - 物理存储：具有相同键值的元组在物理存储上是连续的（或尽可能连续的）。\n    - 限制：一个基本表只能建立一个聚簇索引。在InnoDB中，主键就是聚簇索引；如果没有主键，InnoDB会选择一个非空的唯一索引作为聚簇索引；如果都没有，InnoDB会生成一个隐藏的6字节rowid作为聚簇索引。\n2.  非聚簇索引（Non-Clustered Index/Secondary Index）：\n    - 特点：索引和数据分开存放，索引结构的叶子节点存储的是主键值（InnoDB）或数据行的物理地址（MyISAM）。\n    - 物理存储：索引中的顺序与数据行的物理顺序无关。需要回表操作才能获取完整数据（InnoDB中通过主键回表）。\n\n索引类型（按逻辑）：\n- 主键索引：特殊的唯一索引，一个表只能有一个，值不能为空，通常自动创建聚簇索引（InnoDB）。\n- 普通索引：最基本的索引，没有任何限制。\n- 联合索引：对多个字段联合建立索引。遵循“最左前缀匹配原则”。\n- 唯一索引：索引列的值必须唯一，但允许为空（可以有多个NULL值）。\n- 空间索引：见结构类型中的描述。"
        },
        {
          "id": "mysql-q5",
          "question": "什么时候需要创建索引？什么时候不需要创建索引？",
          "answer": "什么时候需要创建索引：\n1.  字段有唯一性限制：如主键（PRIMARY KEY）和唯一索引（UNIQUE KEY），可以强制列的唯一性。\n2.  经常用于WHERE查询条件的字段：索引能显著加快数据检索速度。\n3.  经常用于GROUP BY和ORDER BY子句的字段：索引可以帮助排序和分组操作，减少文件排序。\n4.  经常用于JOIN操作的连接字段：能加快表之间的连接速度。\n5.  高选择性字段：指字段的值重复率较低，例如性别字段选择性就低，而身份证号选择性就高。高选择性字段创建索引效果更好。\n6.  需要创建哈希索引的场景：仅做等值查询的字段，键值型访问场景。\n7.  需要创建聚簇索引的场景：\n    - 很少对表进行增删（因为它会调整数据物理存储）。\n    - 很少对变长列进行修改（因为可能导致行溢出和页分裂）。\n    - 经常在一起进行连接的关系可以建立组合索引。\n    - 经常出现在相等比较条件中的一组属性。\n    - 值重复率比较高的属性（但选择性低会影响效率，需权衡）。\n\n什么时候不需要创建索引：\n1.  低选择性字段：字段值重复率高，例如性别（男/女），索引的效果会很差，甚至不如全表扫描。\n2.  表数据量非常少：对于小表，全表扫描的开销可能比走索引更小。\n3.  列频繁更新：索引的维护成本很高（增、删、改都需要更新索引）。如果某个列经常更新，索引带来的写操作开销可能超过读操作的收益。\n4.  经常全表扫描的表：如果一个表的大部分查询都是全表扫描，那么索引作用不大。\n5.  不经常使用的列：为不经常使用的列创建索引是浪费存储空间和维护成本。"
        },
        {
          "id": "mysql-q6",
          "question": "MVCC（多版本并发控制）机制是什么？",
          "answer": "MVCC（Multi-Version Concurrency Control）多版本并发控制是InnoDB存储引擎用于处理并发事务的一种技术。它通过保存数据在某个时间点的快照，使得读操作可以访问数据的旧版本，从而在很大程度上实现读写操作的非阻塞，提高了数据库的并发性能。\n\nMVCC的两个重要字段：\n对于InnoDB中的每一行记录，除了用户定义的列，还会自动添加几个隐藏列：\n- DB_TRX_ID (Transaction ID)：最近一次修改（插入或更新）当前行的事务ID。每次事务对数据进行修改时，都会把自己的事务ID赋值给这个字段。\n- DB_ROLL_PTR (Roll Pointer)：回滚指针，指向Undo Log中的上一个版本记录。通过这个指针，可以找到该行数据的所有历史版本，形成一个版本链（或称为历史修改链表）。\n\nMVCC的工作原理：\n- 版本链：当数据被修改时，数据库不会立即覆盖旧版本，而是创建一个新的版本。旧版本的数据会通过DB_ROLL_PTR指针连接到Undo Log中，形成一个由新到旧的版本链。\n- 快照读（Snapshot Read）：在可重复读（Repeatable Read）和读已提交（Read Committed）隔离级别下，普通的SELECT语句（不加锁）执行的是快照读。事务根据自己的开始时间戳（Read View）读取对应版本的数据，确保读到数据的一致性。\n  - 在“读已提交”级别下，每次SELECT语句都会生成一个新的Read View，所以可以看到其他已提交事务的最新数据。\n  - 在“可重复读”级别下，事务只在第一次SELECT时生成一个Read View，之后所有的SELECT都使用这个固定的Read View，从而保证在整个事务期间读取到的数据都是一致的，解决了不可重复读问题。\n- 当前读（Current Read）：对于UPDATE、DELETE、SELECT ... FOR UPDATE、SELECT ... LOCK IN SHARE MODE等语句，会读取数据的最新版本，并对数据加锁，以保证数据的一致性。这个过程会跳过MVCC，直接读取最新已提交的数据（或加上锁的数据）。\n\nMVCC的优点：\n- 读写不冲突：读操作（快照读）不需要加锁，可以直接读取数据的旧版本，不会因为写操作而被阻塞，从而提高了并发性能。\n- 解决并发问题：在“读已提交”和“可重复读”隔离级别下，MVCC有效解决了脏读和不可重复读问题，部分解决了幻读问题（在MySQL的RR级别下，结合间隙锁可以完全解决幻读）。\n- 事务回滚：Undo Log除了支持MVCC，也是事务回滚的关键。"
        },
        {
          "id": "mysql-q7",
          "question": "索引失效的场景有哪些？",
          "answer": "索引失效意味着虽然创建了索引，但在SQL查询中数据库优化器没有使用它，导致全表扫描，降低查询效率。常见的索引失效场景包括：\n1.  在WHERE条件中使用函数：\n    - 例如：`WHERE UPPER(name) = 'TOM'`。对列进行函数操作（包括数学函数、字符串函数、日期函数等），会使索引失效，因为索引保存的是原始列的值，而不是函数处理后的值。正确的做法是在应用层处理或预处理数据。\n2.  类型不一致：\n    - 例如：`WHERE id = '123'` (id列是INT类型)。如果查询条件中的数据类型与索引列的实际类型不一致，MySQL会自动进行类型转换，这会导致索引失效。应确保类型匹配。\n3.  模糊匹配以 % 开头：\n    - 例如：`LIKE '%abc'`。B+树索引本质是“前缀有序”，只适合从左边开始的匹配（如`LIKE 'abc%'`）。如果通配符`%`在开头，索引无法利用其有序性进行查找。\n    - 如果使用`LIKE '%abc%'`，索引也会失效。\n4.  OR条件中部分字段无索引：\n    - 例如：`WHERE name = 'Alice' OR age = 25`，如果name列有索引而age列没有索引，查询优化器为了满足所有OR分支都能走索引，可能会放弃name列的索引而进行全表扫描。\n    - 解决方法是为所有OR条件中的字段都创建索引，或者将OR条件拆分为多个UNION查询。\n5.  组合索引未命中最左前缀：\n    - 遵循最左前缀原则：只有WHERE条件连续包含索引最左的若干列时，组合索引才会生效。\n    - 例如，索引是`(col1, col2, col3)`：\n      - `WHERE col1 = 'a'`：索引生效。\n      - `WHERE col1 = 'a' AND col2 = 'b'`：索引生效。\n      - `WHERE col2 = 'b'`：索引失效（没有最左列`col1`）。\n      - `WHERE col1 = 'a' AND col3 = 'c'`：`col1`部分生效，`col3`不走索引。\n6.  使用`!=` 或 `<>`：\n    - 大多数情况下，使用不等操作符（`!=`、`<>`）会导致索引失效，因为优化器认为这种查询可能涉及大部分数据，走全表扫描更有效。\n7.  使用`IS NULL` 或 `IS NOT NULL`：\n    - 如果列允许为NULL，且`NULL`值分布比较稀疏或密集，`IS NULL`或`IS NOT NULL`可能导致索引失效。这取决于具体的索引类型和数据分布。\n8.  对索引列进行运算：\n    - 例如：`WHERE age + 10 = 30`。与在条件中使用函数类似，对索引列进行算术运算也会导致索引失效。\n9.  MySQL优化器认为全表扫描更快：\n    - 对于数据量很小的表，或者查询结果集占总数据量比例很大的查询，MySQL优化器可能会选择全表扫描，因为它认为索引查找和回表的开销会更大。"
        },
        {
          "id": "mysql-q8",
          "question": "MySQL的执行引擎有哪些？",
          "answer": "MySQL是一个多存储引擎架构的数据库，Server层负责SQL解析、优化等公共服务，而存储引擎层负责数据存储和提取。MySQL主要支持多种存储引擎，最常用的是InnoDB和MyISAM。\n\n1.  InnoDB：\n    - 特点：是MySQL 5.5版本及更高版本的默认存储引擎，支持事务（ACID特性）、行级锁、外键约束、MVCC（多版本并发控制）。数据和索引都存储在同一个`.ibd`文件中。\n    - 优点：可靠性高、并发性能好，适合高并发的事务型应用。\n    - 缺点：占用磁盘空间和内存资源相对较多。\n\n2.  MyISAM：\n    - 特点：早期MySQL的默认存储引擎，不支持事务、行级锁、外键。只支持表级锁，并发性能差。数据存储在`.MYD`文件，索引存储在`.MYI`文件。\n    - 优点：读操作性能高（因为只支持表锁，没有事务开销），占用空间相对较小。\n    - 缺点：不支持事务和崩溃恢复，在高并发写操作下性能差。\n\n3.  Memory：\n    - 特点：将数据存储在内存中，读写速度极快。数据在数据库重启后会丢失。\n    - 优点：极高的访问速度。\n    - 缺点：数据易失，只适合存储临时数据或作为缓存。\n\n4.  Archive：\n    - 特点：用于数据归档，只支持插入和查询操作，不支持更新和删除。对数据进行高度压缩。\n    - 优点：占用磁盘空间小。\n    - 缺点：读写性能差，不适合经常访问的数据。\n\n5.  CSV：\n    - 特点：以CSV（Comma Separated Values）格式存储数据。可以直接读取和写入CSV文件，方便与其他应用程序交换数据。\n    - 优点：数据直接可见，易于导入导出。\n    - 缺点：不支持索引，查询性能差。\n\n总结：在实际应用中，InnoDB是绝大多数MySQL应用的首选存储引擎，因为它提供了事务支持和高并发性能。"
        },
        {
          "id": "mysql-q9",
          "question": "MySQL日志文件有哪几种？它们的作用是什么？",
          "answer": "MySQL的日志文件在数据库的可靠性、数据恢复、复制和审计中扮演着关键角色，主要包括以下几种：\n1.  Undo Log（回滚日志）：\n    - 来源：是InnoDB存储引擎层生成的日志。\n    - 作用：主要用于实现事务的原子性（Atomicity）和MVCC（多版本并发控制）。\n      - **事务回滚**：当事务需要回滚时，Undo Log记录了数据被修改前的旧版本，可以将数据恢复到事务开始前的状态。\n      - **MVCC**：通过Undo Log的历史版本链，使得并发事务可以读取到一致的快照数据，实现了读写不阻塞。\n2.  Redo Log（重做日志）：\n    - 来源：是InnoDB存储引擎层生成的日志。\n    - 作用：主要用于实现事务的持久性（Durability）和崩溃恢复。\n      - **持久性**：当事务提交时，相关的数据修改操作会首先写入Redo Log缓冲区，并尽快刷入磁盘上的Redo Log文件，而不需要等待数据页写入磁盘。这保证了即使数据库崩溃，已提交的事务也不会丢失。\n      - **崩溃恢复**：当数据库从崩溃中恢复时，Redo Log可以用来重放（redo）那些已提交但尚未写入数据文件的数据修改操作，确保数据恢复到一致性状态。\n3.  Binlog（归档日志/二进制日志）：\n    - 来源：是Server层生成的日志，独立于存储引擎。\n    - 作用：主要用于数据备份（Point-in-Time Recovery）和主从复制（Master-Slave Replication）。\n      - **数据备份**：可以结合全量备份，通过重放Binlog来恢复到任意时间点的数据状态。\n      - **主从复制**：主库将Binlog发送给从库，从库通过解析并执行Binlog中的事件来保持与主库的数据同步，实现读写分离和高可用性。\n\n4.  Error Log（错误日志）：记录了MySQL服务器启动、运行和停止时发生的错误、警告和事件信息。\n5.  General Query Log（通用查询日志）：记录了所有来自客户端的SQL请求（包括SELECT）。通常用于调试和审计，但在生产环境中不建议长时间开启，因为它会产生大量I/O开销。\n6.  Slow Query Log（慢查询日志）：记录了执行时间超过预设阈值（`long_query_time`）的SQL查询语句。用于发现和优化性能瓶颈。"
        },
        {
          "id": "mysql-q10",
          "question": "MySQL有哪些锁？",
          "answer": "MySQL的锁机制用于管理并发访问，确保数据的一致性和完整性。锁可以从不同维度进行分类：\n\n按乐观/悲观程度：\n1.  悲观锁（Pessimistic Lock）：\n    - 概念：假设并发冲突必然发生，因此在访问数据前就先加锁，阻止其他事务对数据的修改，直到当前事务释放锁。是一种“先取锁，再访问”的策略。\n    - 典型实现：数据库的行级锁、表级锁等。\n2.  乐观锁（Optimistic Lock）：\n    - 概念：假设冲突极少发生，读取数据时不加锁，仅在更新时检查数据是否被其他事务修改过。通常通过版本号（version字段）或时间戳实现。如果发现数据已被修改，则回滚或重试。\n    - 典型实现：在应用层通过版本号字段控制，或数据库提供的某些CAS（Compare And Swap）操作。\n\n按锁粒度：\n1.  全局锁（Global Lock）：\n    - 概念：对整个数据库实例加锁，使整个数据库处于只读状态。\n    - 应用：主要应用于全库逻辑备份（如`mysqldump --single-transaction`在InnoDB下通过MVCC避免全局锁，但在MyISAM等无事务引擎下会使用）。\n    - 影响：加锁期间，所有对数据库的写操作（包括数据修改DDL、数据查询DML等）以及非事务性的读操作都会被阻塞，影响非常大。\n2.  表级锁（Table Lock）：\n    - 概念：对整张表加锁。\n    - 应用：MyISAM存储引擎的默认锁机制；InnoDB在DDL操作时使用。\n    - 类型：\n      - 表共享读锁（Table Read Lock）：允许并发读，但禁止写。\n      - 表独占写锁（Table Write Lock）：独占，禁止其他任何读写操作。\n    - 优点：开销小，加锁速度快。\n    - 缺点：并发度低，容易发生锁冲突。\n3.  行级锁（Row Lock）：\n    - 概念：对数据行进行加锁。\n    - 应用：InnoDB存储引擎特有的锁机制。\n    - 类型：\n      - 共享锁 / 读锁 / S锁（Share Lock）：对资源加上S锁的事务只能读，其他事务也可以对同一资源加S锁，但不能加X锁。\n      - 排他锁 / 写锁 / X锁（Exclusive Lock）：对资源加上X锁后，其他任何事务都不能对该资源加S锁或X锁。X锁是独占的。\n    - 优点：锁粒度小，并发度高。\n    - 缺点：开销大，加锁慢，可能出现死锁。\n\n其他锁（InnoDB特有）：\n- 意向锁（Intention Lock）：InnoDB在加表级锁时，会先加意向锁，表示事务打算在表或行级别上加锁。分为意向共享锁（IS Lock）和意向排他锁（IX Lock）。\n- 记录锁（Record Lock）：锁住索引记录本身。\n- 间隙锁（Gap Lock）：锁住索引记录之间的间隙，防止其他事务插入新的记录，用于解决可重复读隔离级别下的幻读问题。\n- 临键锁（Next-Key Lock）：是记录锁和间隙锁的组合，锁住一个索引记录以及它前面的间隙。这是InnoDB默认的行锁类型，主要用于解决幻读问题。\n- 插入意向锁（Insert Intention Lock）：在插入新记录时，先在插入位置设置一个插入意向锁。当多个事务在同一个间隙插入数据时，如果插入位置不冲突，它们之间无需互相等待。"
        },
        {
          "id": "mysql-q11",
          "question": "数据库范式（Normal Form）有哪些？",
          "answer": "数据库范式是关系型数据库设计的一组规则，旨在消除数据冗余，保证数据完整性，并减少数据异常。常见的范式有：\n1.  第一范式（1NF）：\n    - 定义：数据库表中的每一列都是不可分割的原子值，即列中不能再包含其他复杂的结构或多个值。\n    - 示例：如果一列“电话号码”存储了“123-4567, 890-1234”，则不符合1NF。应拆分为多列或多行。\n2.  第二范式（2NF）：\n    - 定义：在满足1NF的基础上，表中的所有非主键字段必须完全依赖于整个主键，而不能只依赖于主键的一部分。\n    - 解决：部分函数依赖问题。\n    - 示例：如果主键是`(订单号, 商品号)`，而“商品名称”只依赖于“商品号”，则不符合2NF。应将商品信息拆分到独立的商品表。\n3.  第三范式（3NF）：\n    - 定义：在满足2NF的基础上，表中的所有非主键字段不能依赖于其他非主键字段（即不能存在传递函数依赖）。\n    - 解决：传递函数依赖问题。\n    - 示例：如果表中有`(学生ID, 班级ID, 班级名称)`，主键是“学生ID”，“班级名称”依赖于“班级ID”，“班级ID”依赖于“学生ID”，则“班级名称”间接依赖于主键。应将班级信息拆分到独立的班级表。\n4.  BC范式（BCNF, Boyce-Codd Normal Form）：\n    - 定义：是第三范式的修正，比3NF更严格。要求每个非平凡函数依赖的左边必须是候选键（可以是一个简单候选键，也可以是组合候选键）。简单来说，所有决定因素都必须是候选键。\n    - 解决：当3NF仍不能消除某些函数依赖引起的冗余时（例如，当表中存在多个重叠的候选键时）。\n5.  第四范式（4NF）：\n    - 定义：在满足BCNF的基础上，表中不能存在多值依赖。即如果一个表包含两个或更多个相互独立的多值属性，则需要将它们分解。\n    - 解决：多值依赖。\n6.  第五范式（5NF）：\n    - 定义：在满足4NF的基础上，表必须可以无损分解，且不能有连接依赖。这是最高级别的范式，很少在实际应用中达到。\n\n总结：在实际数据库设计中，通常会设计到3NF或BCNF，因为再高的范式可能导致过度分解，增加JOIN操作的复杂性，影响查询性能。需要在范式化程度和查询性能之间进行权衡。"
        }
      ]
    },
    {
      "id": "network",
      "name": "计算机网络",
      "questions": [
        {
          "id": "network-q1",
          "question": "从输入URL到页面展示，整个过程发生了什么？",
          "answer": "1. URL解析：浏览器解析URL，识别协议、主机名、路径等信息。\n2. DNS查询：\n   - 浏览器缓存 -> 操作系统缓存 -> 路由器缓存 -> ISP DNS服务器。\n   - 如果本地无缓存，ISP DNS服务器进行递归查询：从根域名服务器 -> 顶级域名服务器 -> 权威域名服务器，最终获取到域名对应的IP地址。\n3. TCP连接建立与TLS握手：\n   - 如果是HTTP，建立TCP三次握手连接。\n   - 如果是HTTPS，在TCP连接建立后进行TLS握手，协商加密参数和密钥。\n4. 浏览器发送HTTP请求报文：携带请求方法、URL、请求头、请求体等信息发送给服务器。\n5. 服务器返回HTTP响应报文：包含状态码、响应头、响应体（通常是HTML、CSS、JS等资源）。\n6. 浏览器解析与渲染：\n   - 浏览器解析HTML构建DOM树。\n   - 解析CSS构建CSSOM树。\n   - 将DOM树和CSSOM树结合生成渲染树（Render Tree）。\n   - 计算布局（Layout/Reflow），确定元素位置和大小。\n   - 绘制（Painting），将像素渲染到屏幕上。"
        },
        {
          "id": "network-q2",
          "question": "TCP三次握手的过程是怎样的？",
          "answer": "TCP三次握手用于建立客户端和服务器之间的可靠连接：\n1. 第一次握手 (SYN)：客户端向服务器发送SYN包（同步序列号），并进入SYN_SENT状态，等待服务器确认。\n2. 第二次握手 (SYN+ACK)：服务器收到SYN包后，向客户端发送SYN包和ACK包（确认号），并进入SYN_RECEIVED状态。\n3. 第三次握手 (ACK)：客户端收到服务器的SYN+ACK包后，向服务器发送ACK包，双方都进入ESTABLISHED（已建立连接）状态，可以开始数据传输。"
        },
        {
          "id": "network-q3",
          "question": "TCP四次挥手的过程是怎样的？",
          "answer": "TCP四次挥手用于终止客户端和服务器之间的连接：\n1. 第一次挥手 (FIN)：客户端发送FIN包（终止连接）给服务器，表示客户端没有数据要发送了，进入FIN_WAIT_1状态。\n2. 第二次挥手 (ACK)：服务器收到FIN包后，发送ACK包确认，并进入CLOSE_WAIT状态。客户端收到ACK后，进入FIN_WAIT_2状态。\n3. 第三次挥手 (FIN)：服务器处理完所有数据后，发送FIN包给客户端，表示服务器也没有数据要发送了，进入LAST_ACK状态。\n4. 第四次挥手 (ACK)：客户端收到服务器的FIN包后，发送ACK包确认，进入TIME_WAIT状态。服务器收到ACK后立即关闭连接。客户端在TIME_WAIT状态等待一段时间（2MSL）后，关闭连接，以确保服务器收到ACK并处理延迟数据包。"
        },
        {
          "id": "network-q4",
          "question": "HTTP常见状态码有哪些分类和代表意义？",
          "answer": "HTTP状态码用于表示服务器对请求的处理结果，主要分为以下五类：\n- 1xx 信息响应：表示请求已被接受，需要客户端继续处理或等待。例如：100 Continue。\n- 2xx 成功响应：表示请求已被成功接收、理解、接受。例如：200 OK（请求成功）、201 Created（资源创建成功）、204 No Content（请求成功但无返回内容）。\n- 3xx 重定向：表示需要客户端采取进一步操作才能完成请求。例如：301 Moved Permanently（永久重定向）、302 Found（临时重定向）、304 Not Modified（协商缓存命中，资源未修改）。\n- 4xx 客户端错误：表示请求存在错误或权限问题，服务器无法或不会处理请求。例如：400 Bad Request（请求语法错误）、401 Unauthorized（未认证）、403 Forbidden（禁止访问）、404 Not Found（资源不存在）。\n- 5xx 服务器错误：表示服务器未能处理请求。例如：500 Internal Server Error（服务器内部错误）、502 Bad Gateway（网关错误）、504 Gateway Timeout（网关超时）。"
        },
        {
          "id": "network-q5",
          "question": "GET和POST请求有什么区别？",
          "answer": "GET和POST是HTTP请求中最常用的两种方法，它们的主要区别在于：\n- 作用不同：GET用于从服务器获取（请求）资源，是幂等的（多次请求结果相同）。POST用于向服务器提交（修改/新增）资源，是非幂等的。\n- 参数传递方式：GET将参数直接拼接在URL后面（URL?key1=value1&key2=value2），参数暴露在URL中。POST将参数放在请求体（Request Body）中，对用户不可见。\n- 数据长度限制：GET的URL长度通常有限制（不同浏览器和服务器有差异，一般小于2KB）。POST对数据长度没有理论上的限制。\n- 缓存：GET请求可以被浏览器主动缓存、回退、收藏。POST请求通常不会被浏览器缓存，每次都需要向服务器发送请求。\n- 安全性：GET参数暴露在URL中，敏感信息不适合用GET传输。POST参数在请求体中，相对更安全（但仍是明文传输，HTTPS才能提供加密）。"
        },
        {
          "id": "network-q6",
          "question": "强缓存和协商缓存的区别及实现方式？",
          "answer": "强缓存：\n- 概念：浏览器直接使用本地缓存资源，不向服务器发送请求，返回200 OK (from cache)。\n- 优点：减轻服务器压力，提高加载速度，提升用户体验。\n- 实现方式：\n  - Expires (HTTP 1.0)：响应头字段，设置资源的绝对过期时间（一个具体的GMT时间）。缺点是受客户端时间影响。\n  - Cache-Control (HTTP 1.1)：响应头字段，更灵活，常用指令：\n    - max-age=<seconds>：设置资源在本地缓存的最长时间（相对时间，以秒为单位）。\n    - public：表示可以被所有缓存（包括CDN）缓存。\n    - private：表示只能被客户端浏览器缓存。\n    - no-cache：强制进行协商缓存。\n    - no-store：禁止任何缓存。\n\n协商缓存：\n- 概念：强缓存失效后，浏览器向服务器验证资源是否更新。如果未更新，服务器返回304 Not Modified，浏览器继续使用本地缓存。如果已更新，服务器返回新资源和200 OK。\n- 实现方式：\n  1. ETag / If-None-Match：\n     - 服务器在响应头中发送ETag: \"abcdef\"（资源内容的唯一标识）。\n     - 浏览器在下次请求时，将ETag值放入请求头If-None-Match: \"abcdef\"发送给服务器。\n     - 服务器对比标识，如果一致，返回304 Not Modified；否则返回新资源和新的ETag。\n  2. Last-Modified / If-Modified-Since：\n     - 服务器在响应头中发送Last-Modified: Fri, 01 Jan 2021 00:00:00 GMT（资源最后修改时间）。\n     - 浏览器在下次请求时，将Last-Modified值放入请求头If-Modified-Since: Fri, 01 Jan 2021 00:00:00 GMT发送给服务器。\n     - 服务器比对时间，如果资源在此时间之后没有修改，返回304 Not Modified；否则返回新资源和新的Last-Modified。"
        },
        {
          "id": "network-q7",
          "question": "HTTP/1.0和HTTP/1.1的主要区别是什么？",
          "answer": "HTTP/1.1在HTTP/1.0的基础上做了多项改进：\n- 持久连接：HTTP/1.1默认开启持久连接（Persistent Connections），即在一个TCP连接上可以发送多个HTTP请求和响应，减少了TCP连接建立和关闭的开销（HTTP/1.0默认短连接）。\n- 管道化 (Pipelining)：允许客户端在一个持久连接上发送多个请求而无需等待每个响应的返回（但实际应用中受队头阻塞和实现复杂性影响，用得较少）。\n- 缓存管理：HTTP/1.1引入了更完善的缓存控制机制（如Cache-Control、ETag），而HTTP/1.0只有Expires。\n- 断点续传：HTTP/1.1支持范围请求（Range Requests），允许客户端只请求资源的一部分，实现断点续传。\n- Host头：HTTP/1.1引入了Host头字段，允许一台服务器托管多个域名（虚拟主机），HTTP/1.0不支持。\n- 错误通知：HTTP/1.1引入了更多状态码，提供了更详细的错误报告。"
        },
        {
          "id": "network-q8",
          "question": "HTTP/1.1和HTTP/2.0的主要区别是什么？",
          "answer": "HTTP/2.0旨在解决HTTP/1.1的一些性能瓶颈，主要区别在于：\n- 二进制分帧：HTTP/2.0将HTTP消息分解为独立的帧，并以二进制格式传输，而不是HTTP/1.1的文本格式。这使得解析更高效、更健壮。\n- 多路复用：HTTP/2.0在一个TCP连接上，允许同时发送多个请求和接收多个响应，消除了HTTP/1.1的队头阻塞问题（Head-of-Line Blocking）。\n- 头部压缩 (HPACK)：HTTP/2.0通过对请求头进行压缩（使用静态表和动态表），减少了传输的数据量。\n- 服务器推送 (Server Push)：服务器可以在浏览器请求某个资源之前，主动将它认为客户端可能需要的其他资源推送给客户端，减少了客户端的往返时间。\n- 请求优先级：客户端可以为请求设置优先级，服务器会优先处理高优先级的请求。"
        },
        {
          "id": "network-q9",
          "question": "HTTPS的工作原理是什么？",
          "answer": "HTTPS是HTTP的安全版本，通过TLS/SSL协议对通信进行加密。其工作原理概括如下：\n1. 客户端发起HTTPS请求：浏览器向服务器发起请求。\n2. 服务器发送数字证书：服务器接收到请求后，将配置好的数字证书（包含服务器公钥、证书颁发机构、有效期等信息）发送给客户端。\n3. 客户端验证证书：客户端浏览器内置了受信任的CA（证书颁发机构）根证书。浏览器会用这些根证书验证服务器证书的合法性、有效性、是否被篡改，以及域名是否匹配。\n4. 客户端生成会话密钥并加密：如果证书验证通过，客户端会生成一个随机数（作为对称加密的会话密钥），并使用服务器证书中的公钥对其进行加密。\n5. 客户端发送加密会话密钥：客户端将加密后的会话密钥发送给服务器。\n6. 服务器解密会话密钥：服务器使用自己的私钥解密收到的加密信息，得到客户端生成的会话密钥。\n7. 加密通信：客户端和服务器现在都拥有相同的会话密钥，之后的所有通信都将使用这个会话密钥进行对称加密和解密，确保数据传输的机密性和完整性。"
        },
        {
          "id": "network-q10",
          "question": "HTTPS和HTTP的主要区别？",
          "answer": "HTTPS和HTTP的主要区别在于安全性、端口和证书：\n- 安全性：HTTP是明文传输，数据可能被窃听、篡改。HTTPS通过TLS/SSL协议对通信进行加密，提供数据传输的机密性、完整性和身份认证。\n- 端口号：HTTP默认使用80端口，HTTPS默认使用443端口。\n- 证书：HTTPS需要服务器端配置CA证书（数字证书），用于验证服务器身份和交换加密密钥。HTTP不需要。\n- 性能：HTTPS因涉及加密解密和TLS握手过程，性能开销略高于HTTP，但现代硬件和协议优化已使其影响很小。\n- 连接状态：两者本身都是无状态协议，但通常会结合Cookie等机制实现会话管理。"
        },
        {
          "id": "network-q11",
          "question": "HTTP/2和HTTP/3的主要区别是什么？",
          "answer": "HTTP/3是HTTP协议的最新版本，与HTTP/2相比，最显著的变化是底层传输协议：\n- 底层传输协议：\n  - HTTP/2基于TCP协议。\n  - HTTP/3基于QUIC协议，而QUIC运行在UDP之上。\n- 队头阻塞 (Head-of-Line Blocking)：\n  - HTTP/2虽然通过多路复用解决了应用层的队头阻塞，但仍然受限于TCP底层的队头阻塞（TCP层的一个丢包会阻塞所有流）。\n  - HTTP/3的QUIC协议在UDP上实现了独立的、多路复用的流。这意味着一个流的丢包只影响该流，不会阻塞其他流的传输，大大提升了在丢包和高延迟环境下的性能。\n- 连接建立时间：\n  - TCP+TLS的握手通常需要2-3个RTT（Round-Trip Time）。\n  - QUIC协议集成了TLS握手，首次连接通常只需1个RTT。对于已连接过的服务器，可以实现0-RTT连接恢复，几乎瞬时建立连接。\n- 加密：HTTP/3强制使用TLS 1.3进行加密，提供更强的安全性。\n- 连接迁移：QUIC支持连接迁移，即在网络切换（如从Wi-Fi切换到蜂窝数据）时，客户端IP地址变化，但QUIC连接可以保持不断开，对移动端用户体验有显著提升。"
        },
        {
          "id": "network-q12",
          "question": "DNS的完整查询过程是怎样的？",
          "answer": "DNS（域名系统）查询过程将域名解析为IP地址，通常分为以下步骤：\n1. 浏览器/系统缓存查找：\n   - 浏览器会先检查本地的DNS缓存。\n   - 如果没有，操作系统会检查其本地DNS缓存（hosts文件或系统DNS缓存）。\n   - 如果仍未找到，会向本地DNS服务器（通常由ISP提供或路由器配置）发起DNS查询。\n2. 本地DNS服务器的缓存查找：\n   - 本地DNS服务器收到请求后，会先检查自己的缓存。\n   - 如果找到对应的IP地址，直接返回给客户端。\n3. 迭代查询（如果本地DNS服务器无缓存）：\n   - 本地DNS服务器向根域名服务器发送查询请求，根域名服务器返回顶级域名服务器（如.com, .cn）的IP地址。\n   - 本地DNS服务器再向顶级域名服务器发送查询请求，顶级域名服务器返回权威域名服务器（负责该域名解析的服务器，如google.com的DNS服务器）的IP地址。\n   - 本地DNS服务器最后向权威域名服务器发送查询请求，权威域名服务器返回最终的IP地址。\n4. 返回IP地址并缓存：\n   - 本地DNS服务器将获取到的IP地址返回给客户端，并将其缓存起来。\n   - 客户端浏览器和操作系统也会将此映射关系缓存起来，以便下次快速访问。\n\n注意：有些DNS查询可能是递归查询（客户端向本地DNS服务器发送一次请求，本地DNS服务器负责所有的迭代查询并返回最终结果），但本地DNS服务器向其他DNS服务器的查询通常是迭代查询。"
        },
        {
          "id": "network-q13",
          "question": "TCP和UDP的主要区别是什么？",
          "answer": "TCP和UDP是传输层最重要的两个协议，主要区别如下：\n- 连接性：\n  - TCP：是面向连接的协议。在数据传输前需要通过三次握手建立连接，数据传输后通过四次挥手关闭连接。\n  - UDP：是无连接的协议。发送数据前不需要建立连接。\n- 可靠性：\n  - TCP：提供可靠的数据传输服务。通过序列号、确认应答、重传机制、流量控制、拥塞控制等保证数据不丢失、不重复、按序到达。\n  - UDP：提供无连接不可靠服务。不保证数据能成功到达目的地，不进行重传，不保证顺序。适用于对实时性要求高、少量丢包可接受的场景（如视频通话、在线游戏）。\n- 通信方式：\n  - TCP：只支持单播（一对一）。\n  - UDP：支持单播、多播（一对多）、广播（一对所有）。\n- 传输效率：\n  - TCP：由于有各种保证机制，传输效率相对较低。\n  - UDP：开销小，传输效率高。\n- 报文头开销：\n  - TCP：头部开销较大，通常为20字节（不含选项）。\n  - UDP：头部开销较小，固定为8字节。\n- 面向字节流/报文：\n  - TCP：是面向字节流的，应用层交给TCP的数据会拆分成TCP认为合适的报文段发送。\n  - UDP：是面向报文的，保留消息边界，应用层发送的每个报文在UDP层封装后作为一个独立的UDP数据报发送。\n- 流量控制与拥塞控制：\n  - TCP：提供流量控制（防止发送方数据发送过快，接收方来不及处理）和拥塞控制（防止过多的数据注入网络，导致网络拥塞）。\n  - UDP：不提供流量控制和拥塞控制。\n\n总结：TCP适用于对可靠性要求高的应用（如文件传输、网页浏览），UDP适用于对实时性要求高、允许少量丢包的应用（如音视频流、DNS查询）。"
        },
        {
          "id": "network-q14",
          "question": "TCP的流量控制是如何实现的？",
          "answer": "TCP的流量控制是为了防止发送方发送数据过快，导致接收方缓冲区溢出而丢包。它通过滑动窗口机制实现：\n1. 窗口大小字段：TCP报文段的头部有一个“窗口大小”（Window Size）字段。这个字段表明了接收方当前还能接收多少字节的数据（即接收方缓冲区中可用的字节数）。\n2. 接收方通告：接收方会不断地将自己缓冲区剩余空间的大小，通过ACK报文段中的“窗口大小”字段告知发送方。\n3. 发送方调整：发送方收到这个值后，就会相应地调整自己发送数据的速率，确保发送的数据量总是在接收方窗口大小的范围内。发送方的发送窗口不能超过接收方通告的窗口大小。\n4. 动态调整：接收方缓冲区的大小是动态变化的，当接收方处理完数据，缓冲区空闲空间变大时，会通告一个更大的窗口；当缓冲区即将满时，会通告一个更小的窗口，甚至为0（零窗口），此时发送方会暂停发送数据，直到收到非零窗口通知。\n\n通过这种机制，TCP能够确保数据传输的速度与接收方的处理能力相匹配，避免数据丢失。"
        },
        {
          "id": "network-q15",
          "question": "TCP的拥塞控制是如何实现的？",
          "answer": "TCP的拥塞控制是为了防止过多的数据注入到网络中，导致网络过载，从而引起性能下降（如丢包、延迟增加）。它通过四个核心算法协同工作：慢启动、拥塞避免、快速重传和快速恢复。\n\n核心思想：发送方维护一个“拥塞窗口”（cwnd），其大小根据网络的拥塞情况动态调整，而不是仅仅依赖接收方的窗口大小（流量控制）。\n\n1.  慢启动 (Slow Start)：\n    - 目的：在连接刚建立时或网络恢复时，快速探测网络的可用带宽。\n    - 机制：cwnd从一个较小的值（通常为1或2个MSS）开始。每收到一个ACK，cwnd就指数级增长（增加1个MSS），直到达到慢启动阈值（ssthresh）。\n\n2.  拥塞避免 (Congestion Avoidance)：\n    - 目的：当网络接近或达到饱和时，平滑地增加发送速率。\n    - 机制：当cwnd达到ssthresh后，增长速率会放缓。此时，每经过一个往返时间（RTT），cwnd只线性增加（增加1个MSS）。\n\n3.  拥塞发生（对丢包的响应）：\n    - 快速重传 (Fast Retransmit)：\n      - 触发：发送方收到三个重复的ACK时，认为某个报文段丢失了（而不是等到超时）。\n      - 动作：立即重传这个丢失的报文段，并将ssthresh减半，cwnd设置为新的ssthresh值。\n    - 快速恢复 (Fast Recovery)：\n      - 触发：紧随快速重传之后。\n      - 动作：进入快速恢复阶段，cwnd在新的ssthresh基础上线性增长（每收到一个重复ACK就增加1个MSS）。直到收到针对新数据的ACK，退出快速恢复阶段，cwnd设置为ssthresh，进入拥塞避免阶段。\n    - 超时重传 (Timeout Retransmission)：\n      - 触发：如果发送方等待超时，但没有收到任何ACK，这通常意味着网络状况更糟（可能发生了严重的拥塞，导致大量丢包）。\n      - 动作：将ssthresh减半，cwnd重置为初始值（通常是1个MSS），再次进入慢启动阶段。\n\n通过这些机制，TCP能够动态调整发送速率，在保证高吞吐量的同时，有效避免和缓解网络拥塞。"
        }
      ]
    },
    {
      "id": "golang",
      "name": "golang",
      "questions": [
        {
          "id": "golang-q1",
          "question": "Go语言中 new 关键字的作用是什么？它有什么限制？",
          "answer": "new 关键字在 Go 语言中主要用于内存分配与初始化。\n- 语法：ptr := new(Type)\n- 作用：\n  - 为类型 Type 分配一块内存空间。\n  - 将其初始化为该类型的零值（例如，int 的零值是 0，string 的零值是空字符串，指针的零值是 nil）。\n  - 返回指向该内存的指针 *Type。\n- 限制：new 关键字不适用于 slice、map 和 channel 类型，因为这些类型需要更复杂的初始化过程（如 make 函数）。对于这三种类型，应该使用 make 进行创建和初始化。"
        },
        {
          "id": "golang-q2",
          "question": "Go语言中省略号（...）有哪些用途？",
          "answer": "Go 语言中省略号（...）有多种用途，主要包括：\n- 在函数定义或调用中用于可变参数（Variadic Parameters）。\n  - 作用：允许函数接受零个或多个指定类型的参数。\n  - 示例：func sum(nums...int) int { /* ... */ }\n  - 调用时：可以将多个参数直接传入，或者将一个切片通过 ... 展开后传入，如 sum(1, 2, 3) 或 mySlice := []int{1,2,3}; sum(mySlice...)\n- 在切片字面量里，用来展开切片。\n  - 作用：将一个切片的所有元素作为单独的参数或元素列表添加到另一个切片或函数调用中。\n  - 示例：newSlice := append(slice2, slice1...)"
        },
        {
          "id": "golang-q3",
          "question": "Go语言的包管理机制是怎样的？",
          "answer": "Go语言的包管理主要是通过 Go Modules 实现的。\n- 包的定义：同一文件夹下只能有一个包，包名可以不和文件夹名称一样。\n- Go Modules：以项目为中心管理依赖，解决了 Go 早期版本中 GOPATH 模式的一些痛点。\n- 初始化：通过 go mod init <module-name> 命令初始化 Go Modules，其中 <module-name> 一般是你的项目路径，如 github.com/yourusername/yourproject。执行后会生成 go.mod 文件。\n- go.mod 文件：用来管理项目的模块信息和依赖包及其版本信息。\n- go.sum 文件：记录项目所有直接和间接依赖包的哈希校验和，用于验证依赖包的完整性和安全性。通常在执行 go get、go build 等涉及到实际下载更新依赖包的操作时才会被创建或更新。"
        },
        {
          "id": "golang-q4",
          "question": "Go语言中 Panic 和 Recover 的机制是什么？",
          "answer": "Go语言中的 Panic 和 Recover 是用于处理程序运行时错误的机制。\n- Panic：表示程序无法继续正常运行的严重错误（例如，访问空指针、数组越界）。当 panic 发生时，程序会：\n  1. 依次执行当前 Goroutine 中所有延迟（defer）函数。\n  2. 打印错误信息和调用堆栈（Stack Trace）。\n  3. 调用 os.Exit(2) 结束进程。\n- Recover：是捕获 panic 的机制，让程序从 panic 状态中恢复，避免进程崩溃。它必须写在 defer 函数中，并且只有在 defer 函数被执行时才有效。\n  - 作用：当 panic 发生时，如果当前 Goroutine 的某个 defer 函数调用了 recover()，它会捕获 panic 传入的 error 值，阻止 panic 继续向上扩散（不执行 panic 后的两步：打印堆栈和结束进程），并允许程序继续执行 defer 函数之后的代码。\n  - 注意：recover 只能捕获当前 Goroutine 的 panic。"
        },
        {
          "id": "golang-q5",
          "question": "Go语言切片（Slice）的扩容机制是怎样的？",
          "answer": "Go语言切片是一种动态数组，当使用 append 函数向切片添加元素时，如果当前切片的长度（len）等于其容量（cap），就会触发扩容。\n扩容机制如下：\n1.  判断当前容量：Go运行时会根据当前容量 cap 来决定新的容量。\n2.  扩容策略：\n    - 如果当前容量小于 1024 个元素，通常会以 2 倍的速度扩容（新容量 = 2 * 旧容量）。\n    - 如果当前容量大于或等于 1024 个元素，通常会以 1.25 倍的速度扩容（新容量 = 1.25 * 旧容量），然后向上取整到某个大小。\n    - 具体的扩容因子可能因 Go 版本和底层实现有所调整，但基本原则是小容量翻倍，大容量增长略慢。\n3.  分配新底层数组：根据计算出的新容量，分配一个新的、更大的底层数组。\n4.  数据拷贝：将原切片中的所有数据拷贝到新的底层数组中。\n5.  返回新切片： append 函数返回一个指向新底层数组的切片，其长度和容量都已更新。\n注意：频繁的扩容会涉及数据拷贝，可能带来性能开销。因此，在知道切片大概需要多少容量时，最好在创建时就预分配足够的容量（例如使用 make([]Type, 0, initialCap)）。"
        },
        {
          "id": "golang-q6",
          "question": "Go语言Map的底层实现原理是怎样的？",
          "answer": "Go语言的 Map 底层基于哈希表实现，主要采用链地址法解决哈希冲突，并结合动态扩容机制来保证性能。其核心是两个数据结构：hmap（header）和 bmap（bucket）。\n- hmap：是 Map 的头部结构，包含 Map 的元数据，如：\n  - count：Map 中实际存储的元素数量。\n  - B：决定 bucket 数组的大小，bucket 数组的实际大小为 2^B。\n  - buckets：指向 bucket 数组的指针。\n  - oldbuckets：扩容时指向旧 bucket 数组的指针。\n  - nevacuate：表示扩容进度。\n- bmap：是具体的 bucket（桶）结构。每个 bucket 能够存储最多 8 个 key-value 对。除了存储键值对外，每个 bucket 还有一个 tophash 数组，存储了每个 key 哈希值的高 8 位，用于在 bucket 内快速比较和查找。\n- 哈希冲突解决：当一个 bucket 存储满了 8 个 key-value 对后，会通过 overflow 指针链接到新的 bucket（链地址法）。\n- 查找流程：\n  1. 对 key 进行哈希运算，得到一个 64 位的哈希值。\n  2. 利用哈希值的低 B 位定位到具体的 bucket。\n  3. 利用哈希值的高 8 位在 bucket 的 tophash 数组中快速匹配。如果找到匹配项，则进一步比较完整的 key。如果当前 bucket 满了，则会沿着 overflow 指针链继续查找。\n- 扩容（Grow）：当 Map 的负载因子（实际元素数量 / bucket 数量）超过一定阈值（通常为 6.5）或者存在过多的溢出 bucket 时，Map 会进行扩容操作。扩容会创建一个新的 bucket 数组（通常是旧的两倍），并将旧 bucket 数组中的元素逐步迁移到新数组中，这个迁移过程是渐进式的，以避免一次性大量拷贝数据导致的性能抖动。"
        },
        {
          "id": "golang-q7",
          "question": "协程 (Coroutine) 和 Go 的 Goroutine 有什么区别？",
          "answer": "协程（Coroutine）是一个更广义的概念，指的是一种用户态的轻量级线程，可以在程序中被暂停和恢复执行，且切换开销很小。\n\nGo的Goroutine是在协程概念基础上进行了优化和封装，成为Go并发调度的基本执行单位。\n主要区别和优化点如下：\n- 映射关系：\n  - 传统协程：通常存在 M:1 的映射关系，即多个协程运行在同一个内核级线程上。一个协程阻塞会导致从属同一线程的所有协程无法执行。\n  - Go Goroutine：与线程之间是 M:N（多对多）的映射关系。Goroutine 在少量操作系统线程上进行多路复用，Go 调度器（Scheduler）动态维护 Goroutine 和线程之间的关系。\n- 并行性：\n  - 传统协程：由于只绑定一个线程，无法真正利用多核CPU实现并行。\n  - Go Goroutine：通过 Go 调度器可以利用多个操作系统线程（M），从而实现真正的并行执行（在多核CPU上）。\n- 内核透明性：\n  - 传统协程：对于内核来说通常是透明的，内核只能看到线程，协程的操作都在用户态完成。\n  - Go Goroutine：同样在用户态运行，对内核透明，但 Go 运行时（runtime）负责其调度，使得它能与操作系统线程进行有效协作。\n- 栈大小：\n  - Go Goroutine：拥有动态可调整的栈大小（初始仅几KB），根据需要自动增长和收缩，减少了内存浪费，也避免了栈溢出。传统线程的栈大小通常固定且较大。\n\n总结：Goroutine 是 Go 语言在语言层面提供的并发原语，通过内置的调度器实现了高效的并发和并行，解决了传统协程的一些限制，提供了更便捷、高效的并发编程体验。"
        },
        {
          "id": "golang-q8",
          "question": "Go语言中 sync.WaitGroup 的作用和用法？",
          "answer": "sync.WaitGroup 是 Go 语言标准库 sync 包提供的一个同步原语，主要用于解决在主 Goroutine 启动多个子 Goroutine 后，如何确保主 Goroutine 不会提前退出，而是等待所有子 Goroutine 都完成工作的问题。\n\n作用：它通过一个计数器来实现等待。\n- Add(delta int)：计数器加 delta。通常在启动 Goroutine 之前调用，表示有多少个 Goroutine 需要等待。\n- Done()：计数器减 1。通常在子 Goroutine 完成工作时调用（常配合 defer）。\n- Wait()：阻塞当前 Goroutine，直到计数器归零。\n\n用法示例：\nvar wg sync.WaitGroup\nfor i := 0; i < N; i++ {\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        // 执行任务\n    }()\n}\nwg.Wait() // 主Goroutine等待所有子Goroutine完成"
        },
        {
          "id": "golang-q9",
          "question": "什么是工作池（Worker Pool），为什么需要它？",
          "answer": "工作池（Worker Pool）是一种并发设计模式，它预先创建一组（固定数量的）Goroutine（或线程），这些 Goroutine 称为“工作者”（Workers），它们持续地从一个共享的任务队列中获取任务并执行。当没有任务时，工作者会等待；当有新任务时，它们会被唤醒执行。\n\n为什么需要工作池：\n- 控制 Goroutine 数量，防止资源耗尽：在高并发场景下，如果为每个任务都创建一个新的 Goroutine，可能会导致 Goroutine 数量暴增，消耗大量内存，甚至导致系统崩溃。\n- 复用 Goroutine，减少创建和销毁开销：创建和销毁 Goroutine 虽然比线程开销小，但在处理大量短生命周期任务时，这些开销累积起来依然可观。工作池复用 Goroutine，避免了重复创建销毁。\n- 限制并发度：可以精确控制同时执行的任务数量，避免过载后端服务或资源（如数据库连接、文件句柄等）。\n- 提高响应速度：预创建的 Goroutine 可以在任务到达时立即开始执行，无需等待 Goroutine 的创建。\n- 任务排队与流量削峰：当任务量超出工作池的处理能力时，任务可以在队列中等待，起到流量削峰的作用。"
        },
        {
          "id": "golang-q10",
          "question": "Go语言的GMP调度模型是怎样的？",
          "answer": "Go语言的并发调度模型是GMP模型，它由 Goroutine (G)、逻辑处理器 (P) 和操作系统线程 (M) 三部分组成，旨在高效地调度 Goroutine。\n\n1.  G (Goroutine)：\n    - Go语言并发执行的基本单位，是用户态的轻量级线程。每个 go func() 都会创建一个 G。\n    - 包含：函数入口、上下文、栈内存等。\n\n2.  M (Machine / 操作系统线程)：\n    - 内核级线程的抽象，是真正执行 Goroutine 代码的实体。\n    - 负责绑定 P 并执行 P 队列中的 G 的代码。M 只有绑定 P 后才能执行 G。\n    - 默认上限通常为 10000 个（通过 runtime.SetMaxThreads 控制）。\n    - 当 M 执行的 G 发生系统调用（如文件 I/O、网络 I/O）导致阻塞时，M 也会被阻塞。\n\n3.  P (Processor / 逻辑处理器)：\n    - 逻辑处理器，维护一个本地 Goroutine 队列，调度上下文。\n    - 它的数量由 GOMAXPROCS 环境变量控制，决定了同时有多少个 G 可以并行执行（CPU 核心数）。\n    - 每个 P 和一个 M 绑定。P 的主要作用是避免全局锁竞争并优化局部性（每个 P 有自己的本地 G 队列）。\n\n调度流程：\n1.  Goroutine 创建：当执行 go func() 时，新的 G 会被优先放入当前 M 绑定的 P 的本地队列。\n    - 若本地队列已满（默认容量 256），会将本地队列中一半的 G 转移到全局队列。目的：平衡负载，减少锁竞争。\n2.  M 获取 G 执行：\n    - M 必须绑定 P 才能从 P 的本地队列获取 G 并执行其代码。\n    - 调度优先级（M 从哪里获取 G）：\n      - 优先从当前 P 的本地队列获取（无锁操作，效率最高）。\n      - 本地队列为空，则从全局队列获取（需要加锁访问）。\n      - 全局队列也为空，则从其他 P 的本地队列“偷取”一半的 G（work stealing）。\n    - 每个 G 默认最多运行 10ms（由 sysmon 监控，Go 1.14+ 引入），超时会触发抢占式调度。\n3.  G 阻塞时的处理：\n    - G 主动让出 CPU（如 channel 阻塞、time.Sleep）：当前 G 会被挂起，M 会立即寻找下一个 G 执行。\n    - G 发生系统调用（如网络 I/O、文件 I/O）导致 M 阻塞：M 会将 P 释放给其他空闲的 M 使用。当 I/O 就绪后，原先阻塞的 G 会被重新加入到某个 P 的队列中等待执行。"
        },
        {
          "id": "golang-q11",
          "question": "Go语言 Context 包的作用和底层实现？",
          "answer": "Go语言的 Context 包（context.Context）主要用于 Goroutine 之间传递截止时间、取消信号以及请求范围内的值。它是实现对 Goroutine 生命周期管理和请求数据传递的关键。\n\n作用：\n- 取消操作：允许一个 Goroutine 取消正在运行的子 Goroutine，防止资源泄露和不必要的计算。\n- 设置截止时间（Deadline）：可以为一个操作设置一个超时时间，时间到了自动取消操作，防止长时间阻塞或无限等待。\n- 传递值：在请求范围内传递一些公共的、不可变的值，例如认证信息、请求ID等。\n\ncontext.Background()：\n- context.Background() 是 Go 语言 context 包提供的一个基础上下文对象，它是所有上下文（Context）的根节点。\n- 返回一个空的、非 nil 的 Context，通常用作主上下文、顶级上下文或默认上下文。\n- 它永远不会被取消，没有值，也没有截止时间，适合作为 Goroutine 树的起点。\n\nContext底层实现：\nContext 接口定义了四个方法：Deadline()、Done()、Err()、Value()。\n底层实现是一棵 Context 树，每个 Context 都可以派生出子 Context。\n- Done()：返回一个只读的 channel，当 Context 被取消或超时时，该 channel 会关闭，通知所有监听者。\n- Err()：返回 Context 被取消的原因。\n- Value()：返回与 Context 相关的键值对，用于传递与Context相关的键值对。\n- Context 的取消机制是通过一个取消函数（cancel func）实现的。当调用这个函数时，相关 Context 的 Done channel 会关闭，并递归地关闭所有子 Context 的 Done channel，从而传播取消信号。这种机制使得 Context 能够有效地管理 Goroutine 的生命周期。"
        },
        {
          "id": "golang-q12",
          "question": "Go语言 Channel 的分类和底层实现原理是什么？",
          "answer": "Channel 是 Go 语言中用于 Goroutine 之间数据传递和同步的通信机制。它像生产者-消费者模型里，生产者 Goroutine 通过 channel 把生产的数据传递给消费者 Goroutine。\n\nChannel 的分类：\n1.  无缓冲 Channel：\n    - 创建：ch := make(chan int)。创建时不指定缓冲区大小。\n    - 特性：发送和接收操作必须是同步的、阻塞的，即发送方必须等待接收方接收，接收方必须等待发送方发送，否则都会阻塞。这确保了发送和接收的 Goroutine 之间的严格同步。\n2.  有缓冲 Channel：\n    - 创建：ch := make(chan int, 5)。创建时指定缓冲区大小（例如 5）。\n    - 特性：当缓冲区未满时，发送操作是非阻塞的；当缓冲区未空时，接收操作是非阻塞的。只有缓冲区满了再发送，或者缓冲区空了再接收，才会导致阻塞。\n3.  单向 Channel：\n    - 概念：在函数参数中用于限定 Channel 的操作方向，分为只发送 channel (chan<- Type) 和只接收 channel (<-chan Type)。\n    - 作用：提高代码的健壮性和可读性，防止误用。\n\nChannel 的关闭：\n- 使用 close(ch) 关闭 channel。关闭后不能再向 channel 发送数据，但可以继续从 channel 接收数据，直到缓冲区中所有数据都被取完。\n- 可以通过多返回值 value, ok := <-ch 来判断 channel 是否已被关闭（ok 为 false 表示已关闭且无数据）。\n\nChannel 的底层原理：\nChannel 的底层是一个名为 hchan 的结构体，其核心包含：\n- 缓冲区：对于有缓冲 Channel，hchan 内部维护一个环形队列（通过数组实现）作为缓冲区，存储发送方发送但尚未被接收方取走的数据。\n- 操作的原子性：通过一个 sync.Mutex 互斥锁来保护 hchan 结构体，确保在发送和接收操作时的并发安全。\n- 等待队列：\n  - sendq (发送等待队列)：当 Goroutine 尝试向已满的缓冲区发送数据，或者向无缓冲 Channel 发送数据但没有接收方准备好时，发送 Goroutine 会被包装成 sudog 结构体（包含 Goroutine 指针、数据指针等信息），并加入 sendq 队列，进入等待状态。\n  - recvq (接收等待队列)：当 Goroutine 尝试从空的缓冲区读取数据，或者从无缓冲 Channel 接收数据但没有发送方准备好时，接收 Goroutine 会被包装成 sudog 结构体并加入 recvq 队列，进入等待状态。\n当对应的发送或接收条件满足时（如缓冲区有空位或有数据，或有匹配的发送/接收方），Go 调度器会从等待队列中唤醒相应的 Goroutine 继续执行。"
        },
        {
          "id": "golang-q13",
          "question": "Go语言的垃圾回收（GC）机制是怎样的？请描述三色标记法。",
          "answer": "Go语言的垃圾回收器（GC）采用的是并发的、非分代的、基于三色标记法（Tri-color Mark-Sweep）和混合写屏障（Hybrid Write Barrier）的机制，旨在最大程度地减少应用程序的暂停时间（STW）。\n\n三色标记法是其核心算法，将对象分为三种颜色：\n- 白色（White）：初始状态，表示对象未被GC访问到，被认为是潜在的垃圾。\n- 灰色（Gray）：表示对象已被GC访问到，但其引用的所有子对象（字段）尚未被扫描。\n- 黑色（Black）：表示对象已被GC访问到，并且其所有引用的子对象也已经被扫描。\n\nGC的步骤（三色标记法）大致如下：\n1.  初始标记（Initial Mark）：（短暂 STW）\n    - GC 会暂停用户程序（STW），从根对象（全局变量、栈上的对象、寄存器等）开始，将所有直接可达的对象标记为灰色，其余对象保持白色。\n    - 这个阶段非常短暂，只标记直接可达对象。\n2.  并发标记（Concurrent Mark）：\n    - GC 恢复用户程序，与用户程序并发执行。GC 会遍历灰色对象，将其引用的对象标记为灰色，并将其自身标记为黑色。这个过程会持续进行，直到没有灰色对象为止。\n    - 在这个阶段，由于用户程序也在运行，可能修改对象的引用关系，导致GC遗漏对象。Go通过“混合写屏障”来解决这个问题。\n3.  重标记 / 最终标记（Re-mark / Final Mark）：（短暂 STW）\n    - GC 再次暂停用户程序（STW）。这个阶段是为了处理并发标记阶段中，用户程序对对象引用关系可能造成的“漏标”问题。\n    - Go 1.8+ 采用“混合写屏障”：当黑色对象引用白色对象时，写屏障会将白色对象标记为灰色。当灰色对象被修改时，写屏障会将新旧引用都标记为灰色。这保证了所有可达对象最终都会被标记为灰色或黑色。\n    - 最终标记阶段会重新扫描根对象，并处理所有被写屏障标记为灰色的对象，确保所有可达对象都被正确标记。\n4.  并发清扫（Concurrent Sweep）：\n    - GC 恢复用户程序，与用户程序并发执行。GC 会清扫所有仍然是白色的对象，回收它们占用的内存。\n    - 清扫完成后，GC 会进入等待下一个GC周期的状态。\n\n总结：Go 的 GC 机制通过并发标记和写屏障技术，最大程度地减少了 STW 时间，使得 GC 对应用程序性能的影响非常小，提供了良好的并发编程体验。"
        },
        {
          "id": "golang-q14",
          "question": "Go语言中的条件编译（Build Tags）是什么？如何使用？",
          "answer": "Go语言中的条件编译（Conditional Compilation），通过 Build Tags（构建标签）实现，它允许开发者根据不同的构建环境（如操作系统、架构、Go版本、自定义标签）来决定哪些源文件应该被编译进最终的可执行文件。\n\nBuild Tag 语法：\n- 每个 Go 源文件的开头可以包含一行或多行以 // +build 开头的注释。这些注释行包含构建约束（或称为构建标签）。\n- 示例：\n  // +build prod  // 只有在构建时指定了 'prod' 标签时才编译此文件\n  // +build !prod // 只有在构建时没有指定 'prod' 标签时才编译此文件\n  // +build linux,amd64 // 只有在 Linux 系统且 AMD64 架构下才编译此文件（逗号表示AND关系）\n  // +build debug OR release // 只有在 'debug' 或 'release' 标签存在时才编译此文件（空格表示OR关系）\n\n使用方式：\n- 在 Go 命令（go build, go test 等）后面使用 -tags 参数来指定构建标签。\n- 示例：\n  - go build -tags 'prod'：将编译带有 // +build prod 标签的文件。\n  - go build -tags 'linux debug'：将编译带有 // +build linux 和 // +build debug 标签的文件。\n\n作用：\n- 跨平台开发：为不同操作系统或架构编写特定代码。\n- 环境区分：为开发、测试、生产等不同环境编译不同的代码（如配置加载、模拟数据等）。\n- 功能开关：根据需求选择性地编译某些功能模块。\n\n注意：\n- 构建标签必须放在文件顶部，并且其前面不能有空行或任何其他代码。\n- 标签之间用空格表示 OR 关系，用逗号表示 AND 关系。"
        }
      ]
    },
    {
      "id": "scenario",
      "name": "场景题",
      "questions": [
        {
          "id": "scenario-q1",
          "question": "如何设计一个高并发的秒杀系统？",
          "answer": "高并发秒杀系统设计需要考虑多方面：前端优化（CDN、动静分离）、后端架构（负载均衡、服务拆分）、缓存（Redis预热、多级缓存）、消息队列（削峰填谷、异步处理）、数据库（分库分表、读写分离）、限流与降级、库存扣减优化（悲观/乐观锁、原子操作）等。"
        }
      ]
    },
    {
      "id": "redis",
      "name": "redis",
      "questions": [
        {
          "id": "redis-q1",
          "question": "Redis 的概念和主要数据类型有哪些？",
          "answer": "Redis 是一个高性能、高并发的内存型键值存储系统，它通常被用作数据库、缓存和消息队列。\n\nRedis 中存储的是键值对（Key-Value Pair），其中键（Key）只有字符串类型，而值（Value）支持多种复杂的数据结构：\n- String（字符串）：最基本的数据类型，可以存储字符串、整数或浮点数。内部编码可以是 int、raw 或 embstr。\n- Hash（哈希表）：存储键值对的集合，类似于编程语言中的 Map。适合存储对象。\n- List（列表）：按插入顺序存储字符串元素的链表，可以从两端进行插入和删除操作。适用于队列、栈等场景。\n- Set（集合）：无序的、不重复的字符串元素集合。支持集合间的交集、并集、差集操作。适用于标签、好友关系等。\n- ZSet（有序集合）：Set 的一个升级版，每个成员都关联一个分数（score），成员是唯一的，分数可以重复。通过分数进行排序。适用于排行榜、带权重的标签等。"
        },
        {
          "id": "redis-q2",
          "question": "Redis 的持久化机制有哪些？",
          "answer": "Redis 的持久化机制是将内存中的数据同步到硬盘上，以解决断电或服务器重启后数据丢失的易失性问题。\nRedis 提供了两种主要的持久化机制：\n1.  AOF 日志（Append Only File）：\n    - 概念：追加式日志，以日志的形式记录 Redis 服务器执行的每一个写操作命令。当服务器重启时，通过重新执行 AOF 日志中记录的所有命令来恢复到之前的状态。\n    - 优点：数据完整性更高，因为每次写操作都会记录。提供了多种同步策略（always、everysec、no）。\n    - 缺点：AOF 文件通常比 RDB 文件大，恢复速度可能较慢。\n2.  RDB 快照（Redis Database Snapshot）：\n    - 概念：Redis 数据库快照，在某个时间点，将内存中的所有数据以二进制的形式保存到磁盘上的一个 RDB 快照文件中（dump.rdb）。服务器重启时，直接加载 RDB 快照文件即可恢复到生成快照时的状态。\n    - 优点：RDB 文件紧凑，文件小，恢复速度快。适合用于灾难恢复和备份。\n    - 缺点：RDB 是某一时刻的数据快照，如果 Redis 崩溃，可能会丢失最后一次快照之后的数据。\n3.  混合持久化方式（Redis 4.0+）：\n    - 概念：结合了 AOF 和 RDB 的优点。在 AOF 重写（rewrite）时，新生成的 AOF 文件不再是纯文本的命令序列，而是将重写前的内存数据以 RDB 格式写入 AOF 文件的开头，之后的所有增量命令继续以 AOF 格式追加到该文件中。\n    - 优点：减少了恢复数据的时间（RDB 部分恢复快），同时使数据尽可能新（AOF 部分记录增量数据），提供了更好的恢复效率和数据完整性平衡。"
        },
        {
          "id": "redis-q3",
          "question": "Redis 实现高可用性的三种方法是什么？",
          "answer": "高可用性是指系统在大部分时间都能正常工作，不因局部故障而中断服务。Redis 实现高可用性主要有以下三种方法：\n\n1.  主从复制（Master-Slave Replication）：\n    - 特点：一个主节点（Master）负责处理所有写操作（以及读操作），并将写命令同步给一个或多个从节点（Slave）。从节点通过复制主节点的数据来保持数据一致性，并主要负责读操作，分担主节点压力。\n    - 具体机制：\n      - 建立连接：从节点通过向主节点发送 SLAVEOF 命令建立复制连接。\n      - 同步阶段：从节点发送 PSYNC 命令给主节点。\n        - 全量同步：初次复制或无法进行部分重同步时，主节点会生成 RDB 文件发送给从节点，从节点加载 RDB 数据。\n        - 增量同步：在网络中断后重新连接时，主节点会将断开期间的命令通过命令传播阶段的 AOF 日志发送给从节点。\n      - 命令传播阶段：主节点继续将新接收到的写命令发送给从节点，从节点执行这些命令，保持与主节点的数据同步。\n    - 缺点：主节点故障时，需要手动干预才能切换，无法自动故障转移。\n\n2.  哨兵模式（Redis Sentinel）：\n    - 目的：解决主从模式下故障自动处理的问题，提供自动故障转移（Failover）功能。\n    - 具体机制：\n      - 哨兵节点：部署一个或多个哨兵进程，它们是特殊的 Redis 实例，不存储数据，只负责监控主从集群。\n      - 监控：哨兵节点会不断地检查主节点、从节点以及其他哨兵节点是否正常工作（发送 PING 命令）。\n      - 故障发现：当主节点出现故障（哨兵通过心跳检测判断），并且有足够数量的哨兵（由配置决定）确认主节点下线时，哨兵会标记主节点为“客观下线”（ODOWN）。\n      - 自动故障转移：哨兵集群会通过选举，推选出一个领导者哨兵。领导者哨兵会从众多从节点中挑选出一个最合适的从节点晋升为主节点（通常是复制偏移量最大、优先级最高的从节点），并通知其他从节点连接新的主节点，同时更新客户端的配置信息。\n      - 通信：哨兵之间相互通信，形成一个哨兵集群，以保证故障发现和故障转移决策的准确性和一致性。\n\n3.  切片集群（Redis Cluster）：\n    - 目的：在提供高可用性的同时，解决海量数据存储和读写性能扩展的问题，实现数据的分片存储。\n    - 特点：将数据分散存储于多个 Redis 服务器（节点），每个节点只存储数据总量的部分。每个主节点下可以有从节点用于故障转移。\n    - 具体机制：\n      - 哈希槽（Hash Slot）：Redis Cluster 共有 16384 个哈希槽（slot）。集群中的每个主节点负责一部分哈希槽。集群通过一个数组存储每个槽由哪个节点负责。\n      - 数据分配：数据插入之前，客户端会先对键（key）进行哈希计算（`CRC16(key) % 16384`），以此决定哪个哈希槽负责该键值对，进而确定数据应该存储在哪个节点上。\n      - 节点发现：新节点加入时，通过三次握手（MEET-PONG-PING）完成节点之间的信息交换和注册。\n      - 故障转移：当某个主节点出现故障时，其对应的从节点会自动晋升为主节点，接管哈希槽，提供了自动故障转移和数据分片的能力。"
        },
        {
          "id": "redis-q4",
          "question": "Redis 的缓存管理机制有哪些？",
          "answer": "Redis 的缓存管理机制主要包括定时删除、惰性删除和内存淘汰策略，以有效管理过期键和有限的内存资源。\n\n1.  定时删除：\n    - 概念：Redis 服务器在内部维护一个定时器，每隔一段时间（例如每秒钟），随机从数据库中取出一定数量的带有过期时间的 key 进行检查，删除其中的已过期 key。\n    - 优点：兼顾了删除效率和对CPU资源的占用。不会像立即删除那样消耗大量CPU，也不会像惰性删除那样造成内存浪费。\n    - 缺点：删除的及时性不完全保证，随机性可能导致某些过期 key 停留时间较长。\n\n2.  惰性删除：\n    - 概念：每次从数据库访问 key 时，都检测该 key 是否已过期。如果过期，则立即删除该 key，并返回空值。\n    - 优点：对 CPU 资源占用较少，只有在访问时才进行检查和删除。\n    - 缺点：如果一个已过期的 key 长期没有被访问，它会一直占用内存资源，造成内存浪费（即内存泄露）。\n\n3.  内存淘汰策略（Eviction Policies）：\n    - 概念：当 Redis 运行内存达到了某个预设的最大内存阀值（maxmemory）时，且有新的数据写入时，就会触发内存淘汰机制，根据配置的策略清除部分内存中的 key，以腾出空间。\n    - 八个方法供用户挑选（常见的）：\n      - noeviction：不淘汰任何键，新写操作会报错。\n      - allkeys-lru：从所有键中选择最近最少使用（LRU）的键进行淘汰。\n      - volatile-lru：从设置了过期时间（volatile）的键中选择最近最少使用（LRU）的键进行淘汰。\n      - allkeys-lfU：从所有键中选择最不经常使用（LFU）的键进行淘汰。\n      - volatile-lfU：从设置了过期时间的键中选择最不经常使用（LFU）的键进行淘汰。\n      - allkeys-random：从所有键中随机淘汰。\n      - volatile-random：从设置了过期时间的键中随机淘汰。\n      - volatile-ttl：从设置了过期时间的键中，选择即将过期（剩余 TTL 最短）的键进行淘汰。\n    - 选择合适的淘汰策略是优化 Redis 缓存性能的关键。"
        },
        {
          "id": "redis-q5",
          "question": "Redis 缓存失效的常见场景有哪些？如何解决？",
          "answer": "缓存失效的常见场景主要包括缓存击穿、缓存雪崩和缓存穿透。\n\n1.  缓存击穿：\n    - 概念：当缓存中一个**热点 key**（访问量非常高）正好过期时，大量的并发请求直接穿透缓存，同时去查询数据库，导致数据库瞬间压力过大甚至崩溃。\n    - 解决方案：\n      - 互斥锁（Mutex）：当发现缓存失效时，只允许第一个请求去查询数据库并重建缓存，其他请求阻塞等待。第一个请求完成后，唤醒其他等待请求从缓存中获取数据。\n      - 永不过期：对于一些访问非常频繁且不允许出现击穿的顶级热点数据，可以设置其永不过期，或者在业务低峰期通过后台线程定期刷新。\n      - 预加载/预热：提前将热点数据加载到缓存中，并设置合理的过期时间，避免其在高峰期过期。\n\n2.  缓存雪崩：\n    - 概念：在短时间内，缓存中**大量的 key** 同时过期，或者 Redis 服务突然宕机。导致所有请求直接打到数据库上，数据库负载瞬间升高，最终崩溃。\n    - 解决方案：\n      - 错峰过期：为不同的 key 设置不同的过期时间，可以在过期时间的基础上加上一个随机值，使它们不会同时过期。\n      - 搭建高可用缓存集群：采用 Redis Sentinel 或 Redis Cluster 模式，提高缓存服务的可用性，避免整个缓存服务宕机。\n      - 限流降级：在业务流量突发时，对系统进行限流，或者启动降级策略，优先保证核心业务可用。\n      - 多级缓存：引入多级缓存，如本地缓存+Redis缓存，降低对Redis的依赖。\n\n3.  缓存穿透：\n    - 概念：数据在缓存和数据库中都不存在。大量的请求查询一个不存在的数据，每次都穿透缓存，直接到达数据库，给数据库带来不必要的压力。\n    - 解决方案：\n      - 布隆过滤器（Bloom Filter）：在数据写入缓存和数据库时，将数据的摘要信息（通过多个哈希函数映射到位数组）存入布隆过滤器。当客户端请求数据时，先经过布隆过滤器判断是否存在。如果布隆过滤器判断数据肯定不存在，则直接返回空，避免查询缓存和数据库。如果判断可能存在，再继续查询。\n      - 空值缓存：当数据在数据库中查询不到时，将这个空值（或一个特定标记）也缓存起来，并设置一个较短的过期时间。下次同样的请求过来，先查缓存，发现是空值就直接返回，避免穿透到数据库。\n      - 参数校验：在应用层对请求参数进行严格校验，过滤掉非法或明显不存在的请求。\n      - 白名单限制：维护一个合法请求的白名单，只有在白名单内的请求才允许通过。"
        },
        {
          "id": "redis-q6",
          "question": "Redis 键空间通知（Keyspace Notifications）是什么？如何使用？",
          "answer": "Redis 键空间通知（Keyspace Notifications）是 Redis 提供的一个功能，允许应用程序订阅 Redis 数据库中键（Key）的变化事件（如设置、删除、过期等）。这使得应用能够基于 Redis 键的变化来触发某些操作或事件，通常用在缓存失效、事件驱动编程等场景中。\n\n能够监听的事件类型：\nRedis 可以监听多种事件类型，例如：\n- K：键设置（set）、修改（update）\n- E：键过期（expired）\n- D：键删除（del）、淘汰（evicted）\n- A：所有事件\n\n启用键空间通知：\n键空间通知默认是关闭的，需要在 Redis 配置文件中或者通过 CONFIG SET 命令启用。\n例如，要开启对键设置（K）和键过期（E）的所有事件通知，可以使用：\n`CONFIG SET notify-keyspace-events KEA`\n- K：表示键空间事件，即事件名称前缀为 `__keyspace@<db>__` 的事件（例如 `__keyspace@0__:mykey`）。\n- E：表示键事件，即事件名称前缀为 `__keyevent@<db>__` 的事件（例如 `__keyevent@0__:expired`）。\n- A：表示所有事件（all events）。\n\n订阅事件：\n应用程序可以通过 Redis 的 SUBSCRIBE 或 PSUBSCRIBE 命令来订阅这些事件。\n- `SUBSCRIBE __keyevent@0__:expired`：订阅数据库 0 中所有键的过期事件。\n- `PSUBSCRIBE __keyevent@0__:set`：订阅数据库 0 中所有键的设置事件（PSUBSCRIBE 支持模式匹配）。\n\n示例：\n1.  启用通知：`CONFIG SET notify-keyspace-events KEA`\n2.  订阅事件：在一个客户端（例如 `redis-cli` 的另一个实例）执行 `PSUBSCRIBE __keyevent@0__:expired`。\n3.  设置一个带过期时间的键：在原客户端执行 `SET mykey \"hello\" EX 5`。\n4.  等待 5 秒后，订阅的客户端会收到 `__keyevent@0__:expired` 事件通知。\n\n事件处理器注册模式：\n键空间通知的本质就是一种事件处理器注册模式。在这种编程模式下：\n- 事件：代表系统中发生的某种特定动作或变化，这里特指 Redis 中的键变化。\n- 事件处理器：是一个函数或方法（回调函数），用于响应特定事件并执行相应的操作。\n开发者通过注册事件处理器来指定每个事件类型发生时，应该执行什么操作。其核心思想是将事件的触发与事件的处理解耦，增强了代码的可维护性和可扩展性。"
        },
        {
          "id": "redis-q7",
          "question": "什么是 Redis 网络分区（Network Partitioning）？会造成哪些问题？",
          "answer": "Redis 网络分区（Network Partitioning），俗称“脑裂”（Split-Brain），是在分布式系统中，某些节点之间的网络连接出现故障，导致这些节点无法与其他节点正常通信。结果是，原本统一的集群被分割成多个互相隔离的子集群，每个子集群都可能认为自己是“正确”的，导致数据不一致和行为异常。\n\n网络分区可能造成的问题：\n1.  数据不一致：\n    - Redis 是一个单线程模型的数据库，但它同时支持主从复制、分片等特性。在一个主从结构的 Redis 集群中，网络分区可能导致主节点和部分从节点之间无法正常通信。\n    - 如果在分区后，原主节点仍然继续提供服务，并且被部分从节点（或客户端）认为是可用的。同时，哨兵或集群模式可能触发故障转移，将隔离区中的某个从节点提升为新的主节点。这样，在不同的分区中就会出现多个“主节点”。\n    - 这两个主节点都可能接收写操作。当网络恢复时，这些独立接收的写操作数据可能无法合并，导致严重的数据不一致问题，数据难以同步。\n    - 例如，原主节点写入数据，而由于网络分区，某些从节点无法及时获取到这些更新，它们会使用过时的数据来响应请求，从而造成一致性问题。\n2.  请求丢失：\n    - 网络分区会导致部分客户端请求无法到达 Redis 服务器，特别是当客户端连接到被隔离的节点时。在高并发的情况下，网络分区可能会导致大量的请求被丢失，严重影响系统的响应速度和可靠性。\n3.  不一致的视图：\n    - 在分布式系统中，每个节点通常会保持对其他节点的视图（即集群中所有节点的状态信息）。如果由于网络分区，某些节点无法与其他节点通信，那么这些节点将不再得到全局的状态更新，导致不同分区内的节点对集群的整体状态存在不一致的视图。这会影响故障判断和恢复决策的准确性。"
        }
      ]
    }
  ]
}
